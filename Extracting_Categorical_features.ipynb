{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Extracting_Categorical_features.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2baMvy5c9YJ_"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kytwFs49cnwo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eaf0adf-138f-48b2-bc76-07f1cc59e612"
      },
      "source": [
        "# Extract from zip to csv\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "!mkdir dataset\n",
        "base_dir = 'dataset'\n",
        "path = os.path.join(base_dir, 'archive.zip')\n",
        "\n",
        "with zipfile.ZipFile(path, 'r') as zip_file:\n",
        "  zip_file.extractall(base_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘dataset’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCZhM8aF_YCN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "8e362ea2-b3fc-42b2-d83b-a3c812dd6e46"
      },
      "source": [
        "# Read CSV file\n",
        "imdb_df = pd.read_csv(f\"{base_dir}/imdb.csv\")\n",
        "imdb_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Date</th>\n",
              "      <th>Rate</th>\n",
              "      <th>Votes</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Duration</th>\n",
              "      <th>Type</th>\n",
              "      <th>Certificate</th>\n",
              "      <th>Episodes</th>\n",
              "      <th>Nudity</th>\n",
              "      <th>Violence</th>\n",
              "      <th>Profanity</th>\n",
              "      <th>Alcohol</th>\n",
              "      <th>Frightening</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No Time to Die</td>\n",
              "      <td>2021</td>\n",
              "      <td>7.6</td>\n",
              "      <td>107,163</td>\n",
              "      <td>Action, Adventure, Thriller</td>\n",
              "      <td>163</td>\n",
              "      <td>Film</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>-</td>\n",
              "      <td>Mild</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Mild</td>\n",
              "      <td>Mild</td>\n",
              "      <td>Moderate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Guilty</td>\n",
              "      <td>2021</td>\n",
              "      <td>6.3</td>\n",
              "      <td>64,375</td>\n",
              "      <td>Crime, Drama, Thriller</td>\n",
              "      <td>90</td>\n",
              "      <td>Film</td>\n",
              "      <td>R</td>\n",
              "      <td>-</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Severe</td>\n",
              "      <td>None</td>\n",
              "      <td>Moderate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Many Saints of Newark</td>\n",
              "      <td>2021</td>\n",
              "      <td>6.4</td>\n",
              "      <td>27,145</td>\n",
              "      <td>Crime, Drama</td>\n",
              "      <td>120</td>\n",
              "      <td>Film</td>\n",
              "      <td>R</td>\n",
              "      <td>-</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Severe</td>\n",
              "      <td>Severe</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Moderate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Venom: Let There Be Carnage</td>\n",
              "      <td>2021</td>\n",
              "      <td>6.4</td>\n",
              "      <td>30,443</td>\n",
              "      <td>Action, Adventure, Sci-Fi</td>\n",
              "      <td>97</td>\n",
              "      <td>Film</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>-</td>\n",
              "      <td>None</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Mild</td>\n",
              "      <td>Moderate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dune</td>\n",
              "      <td>2021</td>\n",
              "      <td>8.3</td>\n",
              "      <td>84,636</td>\n",
              "      <td>Action, Adventure, Drama</td>\n",
              "      <td>155</td>\n",
              "      <td>Film</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>-</td>\n",
              "      <td>None</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>None</td>\n",
              "      <td>Mild</td>\n",
              "      <td>Moderate</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Name  Date Rate  ... Profanity   Alcohol Frightening\n",
              "0               No Time to Die  2021  7.6  ...      Mild      Mild    Moderate\n",
              "1                   The Guilty  2021  6.3  ...    Severe      None    Moderate\n",
              "2    The Many Saints of Newark  2021  6.4  ...    Severe  Moderate    Moderate\n",
              "3  Venom: Let There Be Carnage  2021  6.4  ...  Moderate      Mild    Moderate\n",
              "4                         Dune  2021  8.3  ...      None      Mild    Moderate\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUy0aUJnYRs_",
        "outputId": "a661fc48-dfb8-4ab4-b9e5-56aa44ab826a"
      },
      "source": [
        "imdb_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6178 entries, 0 to 6177\n",
            "Data columns (total 14 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   Name         6178 non-null   object\n",
            " 1   Date         6178 non-null   int64 \n",
            " 2   Rate         6178 non-null   object\n",
            " 3   Votes        6178 non-null   object\n",
            " 4   Genre        6178 non-null   object\n",
            " 5   Duration     6178 non-null   object\n",
            " 6   Type         6178 non-null   object\n",
            " 7   Certificate  6178 non-null   object\n",
            " 8   Episodes     6178 non-null   object\n",
            " 9   Nudity       6178 non-null   object\n",
            " 10  Violence     6178 non-null   object\n",
            " 11  Profanity    6178 non-null   object\n",
            " 12  Alcohol      6178 non-null   object\n",
            " 13  Frightening  6178 non-null   object\n",
            "dtypes: int64(1), object(13)\n",
            "memory usage: 675.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Gh1xL5_ceCDG",
        "outputId": "f063ca8e-0730-4763-d64d-65c801574543"
      },
      "source": [
        "# Select several categorical features\n",
        "\n",
        "columns = ['Name', 'Genre', 'Certificate', 'Nudity', 'Violence', 'Profanity']\n",
        "\n",
        "cat_imdb_df = imdb_df[columns]\n",
        "cat_imdb_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Certificate</th>\n",
              "      <th>Nudity</th>\n",
              "      <th>Violence</th>\n",
              "      <th>Profanity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No Time to Die</td>\n",
              "      <td>Action, Adventure, Thriller</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>Mild</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Mild</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Guilty</td>\n",
              "      <td>Crime, Drama, Thriller</td>\n",
              "      <td>R</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Severe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Many Saints of Newark</td>\n",
              "      <td>Crime, Drama</td>\n",
              "      <td>R</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Severe</td>\n",
              "      <td>Severe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Venom: Let There Be Carnage</td>\n",
              "      <td>Action, Adventure, Sci-Fi</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>None</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Moderate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dune</td>\n",
              "      <td>Action, Adventure, Drama</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>None</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Name                        Genre  ...  Violence Profanity\n",
              "0               No Time to Die  Action, Adventure, Thriller  ...  Moderate      Mild\n",
              "1                   The Guilty       Crime, Drama, Thriller  ...      None    Severe\n",
              "2    The Many Saints of Newark                 Crime, Drama  ...    Severe    Severe\n",
              "3  Venom: Let There Be Carnage    Action, Adventure, Sci-Fi  ...  Moderate  Moderate\n",
              "4                         Dune     Action, Adventure, Drama  ...  Moderate      None\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dB9ioFNxfbRE",
        "outputId": "c503e465-95cf-4a70-a207-595040df39f1"
      },
      "source": [
        "cat_imdb_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6178 entries, 0 to 6177\n",
            "Data columns (total 6 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   Name         6178 non-null   object\n",
            " 1   Genre        6178 non-null   object\n",
            " 2   Certificate  6178 non-null   object\n",
            " 3   Nudity       6178 non-null   object\n",
            " 4   Violence     6178 non-null   object\n",
            " 5   Profanity    6178 non-null   object\n",
            "dtypes: object(6)\n",
            "memory usage: 289.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSmDqvs5XJLb"
      },
      "source": [
        "# Brief analysis of the features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exjcSoacgCGE",
        "outputId": "0ca8b364-b6ee-4a2b-c7bd-e6f4afcbed86"
      },
      "source": [
        "cat_imdb_df[\"Name\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "King Kong                                          5\n",
              "The Equalizer                                      4\n",
              "Robin Hood                                         4\n",
              "Get Shorty                                         4\n",
              "Lost in Space                                      4\n",
              "                                                  ..\n",
              "Master and Commander: The Far Side of the World    1\n",
              "Gentleman Jack                                     1\n",
              "Good Grief                                         1\n",
              "Chicago P.D.                                       1\n",
              "Star Wars                                          1\n",
              "Name: Name, Length: 4820, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkCMTmq0gcZE",
        "outputId": "45c7ec54-81c8-40be-8b89-cf6ed2caeeb4"
      },
      "source": [
        "cat_imdb_df[\"Genre\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Comedy                              268\n",
              "Drama                               259\n",
              "Crime, Drama, Mystery               220\n",
              "Comedy, Drama                       199\n",
              "Drama, Romance                      189\n",
              "                                   ... \n",
              "Documentary, Reality-TV, Romance      1\n",
              "Comedy, Mystery, Sci-Fi               1\n",
              "Documentary, History, Reality-TV      1\n",
              "Musical, Romance                      1\n",
              "Adventure, Mystery, Thriller          1\n",
              "Name: Genre, Length: 377, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjEaOal0gjh1",
        "outputId": "226efc7f-a23b-430e-d7fb-5c84793b0e03"
      },
      "source": [
        "cat_imdb_df[\"Certificate\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "R            1885\n",
              "PG-13        1147\n",
              "TV-MA         641\n",
              "TV-14         575\n",
              "PG            530\n",
              "None          450\n",
              "TV-PG         336\n",
              "Not Rated     231\n",
              "TV-G           95\n",
              "G              70\n",
              "Approved       42\n",
              "Unrated        40\n",
              "TV-Y7          34\n",
              "Passed         24\n",
              "NC-17          14\n",
              "TV-Y           13\n",
              "E              12\n",
              "(Banned)       11\n",
              "TV-Y7-FV       11\n",
              "X               6\n",
              "GP              6\n",
              "M               3\n",
              "M/PG            2\n",
              "Name: Certificate, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQdsDbozgoRI",
        "outputId": "16a1f1bb-c524-42de-c93c-736ccbcf679a"
      },
      "source": [
        "cat_imdb_df[\"Nudity\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Mild        2292\n",
              "None        1459\n",
              "Moderate    1251\n",
              "No Rate      707\n",
              "Severe       469\n",
              "Name: Nudity, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnKteAhyg1n1",
        "outputId": "cbc145d0-5d3f-444b-ffaf-f142c1d9efbe"
      },
      "source": [
        "cat_imdb_df[\"Violence\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Moderate    1814\n",
              "Mild        1703\n",
              "Severe      1228\n",
              "No Rate      759\n",
              "None         674\n",
              "Name: Violence, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vN1_8zGAg6xV",
        "outputId": "86fb7615-5c55-4728-e0e7-a05968b915aa"
      },
      "source": [
        "cat_imdb_df[\"Profanity\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Mild        2077\n",
              "Moderate    1646\n",
              "Severe      1052\n",
              "No Rate      745\n",
              "None         658\n",
              "Name: Profanity, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyT1LGK0XB5u"
      },
      "source": [
        "# Pandas facilities for encoding of categorical features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89V33SnphA2f",
        "outputId": "e82eee00-9f18-4aee-a1c5-48f7a97bb620"
      },
      "source": [
        "cat_imdb_df_1 = cat_imdb_df.copy()\n",
        "\n",
        "# Categorical features to ints\n",
        "\n",
        "cat_imdb_df_1[[\"Nudity\", \"Violence\"]] = cat_imdb_df_1[[\"Nudity\", \"Violence\"]].astype('category')\n",
        "cat_imdb_df_1.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6178 entries, 0 to 6177\n",
            "Data columns (total 6 columns):\n",
            " #   Column       Non-Null Count  Dtype   \n",
            "---  ------       --------------  -----   \n",
            " 0   Name         6178 non-null   object  \n",
            " 1   Genre        6178 non-null   object  \n",
            " 2   Certificate  6178 non-null   object  \n",
            " 3   Nudity       6178 non-null   category\n",
            " 4   Violence     6178 non-null   category\n",
            " 5   Profanity    6178 non-null   object  \n",
            "dtypes: category(2), object(4)\n",
            "memory usage: 205.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uWmYhUKNprIW",
        "outputId": "290a7a39-ac84-48a8-e0da-45d03f89e168"
      },
      "source": [
        "cat_imdb_df_1[\"Nudity\"] = cat_imdb_df_1[\"Nudity\"].cat.codes\n",
        "cat_imdb_df_1[\"Violence\"] = cat_imdb_df_1[\"Violence\"].cat.codes\n",
        "cat_imdb_df_1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Certificate</th>\n",
              "      <th>Nudity</th>\n",
              "      <th>Violence</th>\n",
              "      <th>Profanity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No Time to Die</td>\n",
              "      <td>Action, Adventure, Thriller</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Mild</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Guilty</td>\n",
              "      <td>Crime, Drama, Thriller</td>\n",
              "      <td>R</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>Severe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Many Saints of Newark</td>\n",
              "      <td>Crime, Drama</td>\n",
              "      <td>R</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>Severe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Venom: Let There Be Carnage</td>\n",
              "      <td>Action, Adventure, Sci-Fi</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Moderate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dune</td>\n",
              "      <td>Action, Adventure, Drama</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Name                        Genre  ... Violence  Profanity\n",
              "0               No Time to Die  Action, Adventure, Thriller  ...        1       Mild\n",
              "1                   The Guilty       Crime, Drama, Thriller  ...        3     Severe\n",
              "2    The Many Saints of Newark                 Crime, Drama  ...        4     Severe\n",
              "3  Venom: Let There Be Carnage    Action, Adventure, Sci-Fi  ...        1   Moderate\n",
              "4                         Dune     Action, Adventure, Drama  ...        1       None\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9Mo-ovLqA9e",
        "outputId": "de8a0817-edec-4d4c-f46d-5aa42594a1ba"
      },
      "source": [
        "cat_imdb_df_1[\"Nudity\"].dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('int8')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "1r206xXYqXSx",
        "outputId": "d519b677-0c51-4a5a-d3f9-f3fe2b839ae6"
      },
      "source": [
        "# Categorical feature to one-hot\n",
        "\n",
        "obj_df_new = pd.get_dummies(cat_imdb_df_1, columns=[\"Profanity\"])\n",
        "obj_df_new.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Certificate</th>\n",
              "      <th>Nudity</th>\n",
              "      <th>Violence</th>\n",
              "      <th>Profanity_Mild</th>\n",
              "      <th>Profanity_Moderate</th>\n",
              "      <th>Profanity_No Rate</th>\n",
              "      <th>Profanity_None</th>\n",
              "      <th>Profanity_Severe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No Time to Die</td>\n",
              "      <td>Action, Adventure, Thriller</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Guilty</td>\n",
              "      <td>Crime, Drama, Thriller</td>\n",
              "      <td>R</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Many Saints of Newark</td>\n",
              "      <td>Crime, Drama</td>\n",
              "      <td>R</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Venom: Let There Be Carnage</td>\n",
              "      <td>Action, Adventure, Sci-Fi</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dune</td>\n",
              "      <td>Action, Adventure, Drama</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Name  ... Profanity_Severe\n",
              "0               No Time to Die  ...                0\n",
              "1                   The Guilty  ...                1\n",
              "2    The Many Saints of Newark  ...                1\n",
              "3  Venom: Let There Be Carnage  ...                0\n",
              "4                         Dune  ...                0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "Td-WGqhc078c",
        "outputId": "da70b45f-08b4-416f-8f6e-d6b3a96502b0"
      },
      "source": [
        "cat_imdb_df_1 = pd.get_dummies(cat_imdb_df_1, columns=[\"Profanity\"], prefix=[\"prof\"])\n",
        "cat_imdb_df_1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Certificate</th>\n",
              "      <th>Nudity</th>\n",
              "      <th>Violence</th>\n",
              "      <th>prof_Mild</th>\n",
              "      <th>prof_Moderate</th>\n",
              "      <th>prof_No Rate</th>\n",
              "      <th>prof_None</th>\n",
              "      <th>prof_Severe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No Time to Die</td>\n",
              "      <td>Action, Adventure, Thriller</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Guilty</td>\n",
              "      <td>Crime, Drama, Thriller</td>\n",
              "      <td>R</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Many Saints of Newark</td>\n",
              "      <td>Crime, Drama</td>\n",
              "      <td>R</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Venom: Let There Be Carnage</td>\n",
              "      <td>Action, Adventure, Sci-Fi</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dune</td>\n",
              "      <td>Action, Adventure, Drama</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Name  ... prof_Severe\n",
              "0               No Time to Die  ...           0\n",
              "1                   The Guilty  ...           1\n",
              "2    The Many Saints of Newark  ...           1\n",
              "3  Venom: Let There Be Carnage  ...           0\n",
              "4                         Dune  ...           0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uqqv5nd3DDp",
        "outputId": "071f1ae5-7234-4680-fabf-a3abb3437272"
      },
      "source": [
        "cat_imdb_df_1[[\"prof_Mild\", \"prof_Moderate\"]].dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "prof_Mild        uint8\n",
              "prof_Moderate    uint8\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "TJCzaBrW3SDY",
        "outputId": "64880d1a-a273-4b18-b0ca-5b8b2cae6abc"
      },
      "source": [
        "# ints to one-hot\n",
        "\n",
        "cat_imdb_df_1 = pd.get_dummies(cat_imdb_df_1, columns=[\"Violence\"], prefix=[\"viol\"])\n",
        "cat_imdb_df_1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Certificate</th>\n",
              "      <th>Nudity</th>\n",
              "      <th>prof_Mild</th>\n",
              "      <th>prof_Moderate</th>\n",
              "      <th>prof_No Rate</th>\n",
              "      <th>prof_None</th>\n",
              "      <th>prof_Severe</th>\n",
              "      <th>viol_0</th>\n",
              "      <th>viol_1</th>\n",
              "      <th>viol_2</th>\n",
              "      <th>viol_3</th>\n",
              "      <th>viol_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No Time to Die</td>\n",
              "      <td>Action, Adventure, Thriller</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Guilty</td>\n",
              "      <td>Crime, Drama, Thriller</td>\n",
              "      <td>R</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Many Saints of Newark</td>\n",
              "      <td>Crime, Drama</td>\n",
              "      <td>R</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Venom: Let There Be Carnage</td>\n",
              "      <td>Action, Adventure, Sci-Fi</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dune</td>\n",
              "      <td>Action, Adventure, Drama</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Name                        Genre  ... viol_3  viol_4\n",
              "0               No Time to Die  Action, Adventure, Thriller  ...      0       0\n",
              "1                   The Guilty       Crime, Drama, Thriller  ...      1       0\n",
              "2    The Many Saints of Newark                 Crime, Drama  ...      0       1\n",
              "3  Venom: Let There Be Carnage    Action, Adventure, Sci-Fi  ...      0       0\n",
              "4                         Dune     Action, Adventure, Drama  ...      0       0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "MR64m7RB4Jtr",
        "outputId": "3e271bea-6d02-4670-ea28-4cee6f21c618"
      },
      "source": [
        "# Custom Binary encoding\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "cat_imdb_df_1[\"Genre\"] = np.where(cat_imdb_df_1[\"Genre\"].str.contains(\"Drama\"), 1, 0)\n",
        "cat_imdb_df_1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Certificate</th>\n",
              "      <th>Nudity</th>\n",
              "      <th>prof_Mild</th>\n",
              "      <th>prof_Moderate</th>\n",
              "      <th>prof_No Rate</th>\n",
              "      <th>prof_None</th>\n",
              "      <th>prof_Severe</th>\n",
              "      <th>viol_0</th>\n",
              "      <th>viol_1</th>\n",
              "      <th>viol_2</th>\n",
              "      <th>viol_3</th>\n",
              "      <th>viol_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No Time to Die</td>\n",
              "      <td>0</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Guilty</td>\n",
              "      <td>1</td>\n",
              "      <td>R</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Many Saints of Newark</td>\n",
              "      <td>1</td>\n",
              "      <td>R</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Venom: Let There Be Carnage</td>\n",
              "      <td>0</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dune</td>\n",
              "      <td>1</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Name  Genre Certificate  ...  viol_2  viol_3  viol_4\n",
              "0               No Time to Die      0       PG-13  ...       0       0       0\n",
              "1                   The Guilty      1           R  ...       0       1       0\n",
              "2    The Many Saints of Newark      1           R  ...       0       0       1\n",
              "3  Venom: Let There Be Carnage      0       PG-13  ...       0       0       0\n",
              "4                         Dune      1       PG-13  ...       0       0       0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ml1n7T9L5pNE",
        "outputId": "6007e29f-a29e-4c68-cb89-b68f8c617da4"
      },
      "source": [
        "# It should be noted - we have default numpy precision here - int64\n",
        "cat_imdb_df_1[\"Genre\"].dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('int64')"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV3bIRoBW2C-"
      },
      "source": [
        "# Sklearn facilities for encoding of categorical features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oefswUHv5nKW",
        "outputId": "84868add-2735-48d4-afcb-3c756d82387f"
      },
      "source": [
        "cat_imdb_df_2 = cat_imdb_df.copy()\n",
        "\n",
        "cat_imdb_df_2.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Certificate</th>\n",
              "      <th>Nudity</th>\n",
              "      <th>Violence</th>\n",
              "      <th>Profanity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No Time to Die</td>\n",
              "      <td>Action, Adventure, Thriller</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>Mild</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Mild</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Guilty</td>\n",
              "      <td>Crime, Drama, Thriller</td>\n",
              "      <td>R</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Severe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Many Saints of Newark</td>\n",
              "      <td>Crime, Drama</td>\n",
              "      <td>R</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Severe</td>\n",
              "      <td>Severe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Venom: Let There Be Carnage</td>\n",
              "      <td>Action, Adventure, Sci-Fi</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>None</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Moderate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dune</td>\n",
              "      <td>Action, Adventure, Drama</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>None</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Name                        Genre  ...  Violence Profanity\n",
              "0               No Time to Die  Action, Adventure, Thriller  ...  Moderate      Mild\n",
              "1                   The Guilty       Crime, Drama, Thriller  ...      None    Severe\n",
              "2    The Many Saints of Newark                 Crime, Drama  ...    Severe    Severe\n",
              "3  Venom: Let There Be Carnage    Action, Adventure, Sci-Fi  ...  Moderate  Moderate\n",
              "4                         Dune     Action, Adventure, Drama  ...  Moderate      None\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4uqk5IxX56fw",
        "outputId": "21eb42f0-e5d1-4e84-8743-68749a22f8ff"
      },
      "source": [
        "# Categorical features to ints\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# This transformer should be used to encode target values, i.e. y, and not the inputs.\n",
        "label_encoder = LabelEncoder()\n",
        "cat_imdb_df_2[\"Nudity\"] = label_encoder.fit_transform(cat_imdb_df_2[\"Nudity\"])\n",
        "cat_imdb_df_2.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Certificate</th>\n",
              "      <th>Nudity</th>\n",
              "      <th>Violence</th>\n",
              "      <th>Profanity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No Time to Die</td>\n",
              "      <td>Action, Adventure, Thriller</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>0</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Mild</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Guilty</td>\n",
              "      <td>Crime, Drama, Thriller</td>\n",
              "      <td>R</td>\n",
              "      <td>3</td>\n",
              "      <td>None</td>\n",
              "      <td>Severe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Many Saints of Newark</td>\n",
              "      <td>Crime, Drama</td>\n",
              "      <td>R</td>\n",
              "      <td>1</td>\n",
              "      <td>Severe</td>\n",
              "      <td>Severe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Venom: Let There Be Carnage</td>\n",
              "      <td>Action, Adventure, Sci-Fi</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>3</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Moderate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dune</td>\n",
              "      <td>Action, Adventure, Drama</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>3</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Name                        Genre  ...  Violence  Profanity\n",
              "0               No Time to Die  Action, Adventure, Thriller  ...  Moderate       Mild\n",
              "1                   The Guilty       Crime, Drama, Thriller  ...      None     Severe\n",
              "2    The Many Saints of Newark                 Crime, Drama  ...    Severe     Severe\n",
              "3  Venom: Let There Be Carnage    Action, Adventure, Sci-Fi  ...  Moderate   Moderate\n",
              "4                         Dune     Action, Adventure, Drama  ...  Moderate       None\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1fjQ3Fs7PwK",
        "outputId": "6cc76ffb-9c5a-4641-fb5d-4e5d75975bd9"
      },
      "source": [
        "cat_imdb_df_2[\"Nudity\"].dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('int64')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4RqK1Som-74",
        "outputId": "51b9a21a-0ca3-4eff-d611-990a432bd92c"
      },
      "source": [
        "# Categorical features to floats\n",
        "\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "cat_imdb_df_2_1 = cat_imdb_df.copy()\n",
        "\n",
        "# This transformer should be used to encode target values, i.e. y, and not the inputs.\n",
        "ordinal_encoder = OrdinalEncoder()\n",
        "\n",
        "cat_nudity_array = cat_imdb_df_2_1[\"Nudity\"].to_numpy()\n",
        "cat_nudity_array = cat_nudity_array.reshape(-1, 1)\n",
        "cat_nudity_array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Mild'],\n",
              "       ['None'],\n",
              "       ['Moderate'],\n",
              "       ...,\n",
              "       ['Severe'],\n",
              "       ['None'],\n",
              "       ['Mild']], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WEU4F0bFnxhB",
        "outputId": "b64f9596-9a69-476a-c0cc-82ca87d6f66e"
      },
      "source": [
        "cat_imdb_df_2_1[\"Nudity\"] = ordinal_encoder.fit_transform(cat_nudity_array)\n",
        "cat_imdb_df_2_1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Certificate</th>\n",
              "      <th>Nudity</th>\n",
              "      <th>Violence</th>\n",
              "      <th>Profanity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No Time to Die</td>\n",
              "      <td>Action, Adventure, Thriller</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Mild</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Guilty</td>\n",
              "      <td>Crime, Drama, Thriller</td>\n",
              "      <td>R</td>\n",
              "      <td>3.0</td>\n",
              "      <td>None</td>\n",
              "      <td>Severe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Many Saints of Newark</td>\n",
              "      <td>Crime, Drama</td>\n",
              "      <td>R</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Severe</td>\n",
              "      <td>Severe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Venom: Let There Be Carnage</td>\n",
              "      <td>Action, Adventure, Sci-Fi</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Moderate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dune</td>\n",
              "      <td>Action, Adventure, Drama</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Name                        Genre  ...  Violence  Profanity\n",
              "0               No Time to Die  Action, Adventure, Thriller  ...  Moderate       Mild\n",
              "1                   The Guilty       Crime, Drama, Thriller  ...      None     Severe\n",
              "2    The Many Saints of Newark                 Crime, Drama  ...    Severe     Severe\n",
              "3  Venom: Let There Be Carnage    Action, Adventure, Sci-Fi  ...  Moderate   Moderate\n",
              "4                         Dune     Action, Adventure, Drama  ...  Moderate       None\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIIe3dMqofMY",
        "outputId": "c21f4a97-c4e3-4589-d6d8-e61bdb27ebdd"
      },
      "source": [
        "cat_imdb_df_2_1[\"Nudity\"].dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VpYIsNAAQ3KX",
        "outputId": "79deefb8-14bc-435d-eca6-a42a692725cb"
      },
      "source": [
        "# Categorical feature to one-hot\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "label_binarizer = LabelBinarizer()\n",
        "lb_encoded = label_binarizer.fit_transform(cat_imdb_df_2[\"Profanity\"])\n",
        "new_df = pd.DataFrame(lb_encoded, columns=label_binarizer.classes_)\n",
        "new_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mild</th>\n",
              "      <th>Moderate</th>\n",
              "      <th>No Rate</th>\n",
              "      <th>None</th>\n",
              "      <th>Severe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Mild  Moderate  No Rate  None  Severe\n",
              "0     1         0        0     0       0\n",
              "1     0         0        0     0       1\n",
              "2     0         0        0     0       1\n",
              "3     0         1        0     0       0\n",
              "4     0         0        0     1       0"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0z0QRRNL8Obm",
        "outputId": "cf62d9a4-822a-4194-e0cc-0e7d156a4102"
      },
      "source": [
        "# Concatenate two DataFrames\n",
        "\n",
        "cat_imdb_df_3 = pd.concat([cat_imdb_df_2, new_df], axis=1)\n",
        "cat_imdb_df_3.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Certificate</th>\n",
              "      <th>Nudity</th>\n",
              "      <th>Violence</th>\n",
              "      <th>Profanity</th>\n",
              "      <th>Mild</th>\n",
              "      <th>Moderate</th>\n",
              "      <th>No Rate</th>\n",
              "      <th>None</th>\n",
              "      <th>Severe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No Time to Die</td>\n",
              "      <td>Action, Adventure, Thriller</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>0</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Mild</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Guilty</td>\n",
              "      <td>Crime, Drama, Thriller</td>\n",
              "      <td>R</td>\n",
              "      <td>3</td>\n",
              "      <td>None</td>\n",
              "      <td>Severe</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Many Saints of Newark</td>\n",
              "      <td>Crime, Drama</td>\n",
              "      <td>R</td>\n",
              "      <td>1</td>\n",
              "      <td>Severe</td>\n",
              "      <td>Severe</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Venom: Let There Be Carnage</td>\n",
              "      <td>Action, Adventure, Sci-Fi</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>3</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dune</td>\n",
              "      <td>Action, Adventure, Drama</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>3</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Name                        Genre  ... None  Severe\n",
              "0               No Time to Die  Action, Adventure, Thriller  ...    0       0\n",
              "1                   The Guilty       Crime, Drama, Thriller  ...    0       1\n",
              "2    The Many Saints of Newark                 Crime, Drama  ...    0       1\n",
              "3  Venom: Let There Be Carnage    Action, Adventure, Sci-Fi  ...    0       0\n",
              "4                         Dune     Action, Adventure, Drama  ...    1       0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XwSk2SVAAJkG",
        "outputId": "93d390e2-7359-4bce-80d5-509a01932165"
      },
      "source": [
        "cat_imdb_df_3.drop(columns=['Profanity'], inplace=True)\n",
        "cat_imdb_df_3.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Certificate</th>\n",
              "      <th>Nudity</th>\n",
              "      <th>Violence</th>\n",
              "      <th>Mild</th>\n",
              "      <th>Moderate</th>\n",
              "      <th>No Rate</th>\n",
              "      <th>None</th>\n",
              "      <th>Severe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No Time to Die</td>\n",
              "      <td>Action, Adventure, Thriller</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>0</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Guilty</td>\n",
              "      <td>Crime, Drama, Thriller</td>\n",
              "      <td>R</td>\n",
              "      <td>3</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Many Saints of Newark</td>\n",
              "      <td>Crime, Drama</td>\n",
              "      <td>R</td>\n",
              "      <td>1</td>\n",
              "      <td>Severe</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Venom: Let There Be Carnage</td>\n",
              "      <td>Action, Adventure, Sci-Fi</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>3</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dune</td>\n",
              "      <td>Action, Adventure, Drama</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>3</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Name                        Genre  ... None  Severe\n",
              "0               No Time to Die  Action, Adventure, Thriller  ...    0       0\n",
              "1                   The Guilty       Crime, Drama, Thriller  ...    0       1\n",
              "2    The Many Saints of Newark                 Crime, Drama  ...    0       1\n",
              "3  Venom: Let There Be Carnage    Action, Adventure, Sci-Fi  ...    0       0\n",
              "4                         Dune     Action, Adventure, Drama  ...    1       0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRlKagtaArAs",
        "outputId": "3994d140-1d83-4468-bcef-de0546c15bbd"
      },
      "source": [
        "cat_imdb_df_3[\"Mild\"].dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('int64')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaGRB5tceqlY",
        "outputId": "d35ff040-da90-49ca-d6bd-7cb415872436"
      },
      "source": [
        "# Encoding to one-hot using OneHotEncoder\n",
        "\n",
        "cat_profanity_array = cat_imdb_df_2[\"Profanity\"].to_numpy()\n",
        "cat_profanity_array = cat_profanity_array.reshape(-1, 1)\n",
        "cat_profanity_array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Mild'],\n",
              "       ['Severe'],\n",
              "       ['Severe'],\n",
              "       ...,\n",
              "       ['Severe'],\n",
              "       ['Mild'],\n",
              "       ['Severe']], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncXf1yX6sx32",
        "outputId": "003b9544-5132-4333-f438-6d0f526b9ad6"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "categories_encoded = one_hot_encoder.fit_transform(cat_profanity_array)\n",
        "one_hot_encoder.categories_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array(['Mild', 'Moderate', 'No Rate', 'None', 'Severe'], dtype=object)]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fb5-R4fsaxfz",
        "outputId": "af05fe1b-0881-4597-8d67-a93176bc1f40"
      },
      "source": [
        "new_df2 = pd.DataFrame(categories_encoded, columns=one_hot_encoder.categories_[0])\n",
        "new_df2.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mild</th>\n",
              "      <th>Moderate</th>\n",
              "      <th>No Rate</th>\n",
              "      <th>None</th>\n",
              "      <th>Severe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Mild  Moderate  No Rate  None  Severe\n",
              "0   1.0       0.0      0.0   0.0     0.0\n",
              "1   0.0       0.0      0.0   0.0     1.0\n",
              "2   0.0       0.0      0.0   0.0     1.0\n",
              "3   0.0       1.0      0.0   0.0     0.0\n",
              "4   0.0       0.0      0.0   1.0     0.0"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khqTS3VTrLOV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efe3f358-2e25-4b51-cb8e-3e66e3813c7e"
      },
      "source": [
        "new_df2[\"Mild\"].dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkdkKl_YqmVN"
      },
      "source": [
        "One of the big benefits of using OneHotEncoder with Scikit Learn models is that you can include it, along with the model itself, as a step in a Scikit Learn Pipeline, essentially bundling One Hot Encoding (and potentially other preprocessing) logic and inference logic as a single deployable artifact."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TobGCdSA6DDE",
        "outputId": "df1fb035-6e35-4431-a794-f670e6f70042"
      },
      "source": [
        "cleanup_nums = {\"Profanity\" : {\n",
        "    \"Mild\": 0,\n",
        "    \"Moderate\": 3,\n",
        "    \"No Rate\": 2,\n",
        "    \"None\": 4,\n",
        "    \"Severe\": 1,\n",
        "    },\n",
        "    }\n",
        "cat_imdb_df_4 = cat_imdb_df_2.copy()\n",
        "cat_imdb_df_4.replace(cleanup_nums, inplace=True)\n",
        "labels = cat_imdb_df_4[\"Profanity\"]\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0\n",
              "1       1\n",
              "2       1\n",
              "3       3\n",
              "4       4\n",
              "       ..\n",
              "6173    1\n",
              "6174    4\n",
              "6175    1\n",
              "6176    0\n",
              "6177    1\n",
              "Name: Profanity, Length: 6178, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqZ_LxW0qkZ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9f87ec1-880d-4adf-87d0-abfcfe114bed"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "linear_regression = LinearRegression()\n",
        "pipeline = Pipeline(steps=[('one_hot_encoder',one_hot_encoder), ('linear_regression', linear_regression)])\n",
        "pipeline.fit(cat_profanity_array, labels)\n",
        "\n",
        "print('Severe Prediction:', pipeline.predict([['Severe']])[0])\n",
        "print('Moderate Prediction:', pipeline.predict([['Moderate']])[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Severe Prediction: 1.0000000000000004\n",
            "Moderate Prediction: 3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQUDcVUu8koK"
      },
      "source": [
        "Back to our TensorFlow scenario: if you want to use OneHotEncoder to preprocess input features for a TensorFlow model, you may have some additional complexity to deal with, because you have to:\n",
        "1. Duplicate the One Hot Encoding logic anywhere that the model is used for inference.\n",
        "2. Or, deploy both the fit OneHotEncoder and the trained TensorFlow model as separate artifacts, and then ensure that they are used properly and kept in-sync by all applications that use the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r3_ssmzrRQO"
      },
      "source": [
        "# Sklearn for bag-of-words, n-grams, tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5KKt5zTTOmu",
        "outputId": "e87c367e-cc35-4974-8f58-fe86dd98d4a7"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# class sklearn.feature_extraction.text.CountVectorizer(*, input='content', encoding='utf-8',\n",
        "# decode_error='strict', strip_accents=None, lowercase=True, preprocessor=None,\n",
        "# tokenizer=None, stop_words=None, token_pattern='(?u)\\b\\w\\w+\\b', ngram_range=(1, 1),\n",
        "# analyzer='word', max_df=1.0, min_df=1, max_features=None, vocabulary=None,\n",
        "# binary=False, dtype=<class 'numpy.int64'>)[source]\n",
        "\n",
        "# input='content', the input is expected to be a sequence of items that can be of type string or byte.\n",
        "\n",
        "# strip_accents: {‘ascii’, ‘unicode’}, default=None\n",
        "# Remove accents and perform other character normalization during the preprocessing step.\n",
        "# ‘ascii’ is a fast method that only works on characters that have an direct ASCII mapping.\n",
        "# ‘unicode’ is a slightly slower method that works on any characters.\n",
        "# None (default) does nothing.\n",
        "\n",
        "# lowercase: bool, default=True\n",
        "# Convert all characters to lowercase before tokenizing.\n",
        "\n",
        "# preprocessor: callable, default=None\n",
        "# Override the preprocessing (strip_accents and lowercase) stage while preserving the tokenizing\n",
        "# and n-grams generation steps. Only applies if analyzer is not callable.\n",
        "\n",
        "# tokenizer: callable, default=None\n",
        "# Override the string tokenization step while preserving the preprocessing\n",
        "# and n-grams generation steps. Only applies if analyzer == 'word'.\n",
        "\n",
        "# stop_words: {‘english’}, list, default=None\n",
        "# If ‘english’, a built-in stop word list for English is used.\n",
        "# There are several known issues with ‘english’ and you should consider an alternative.\n",
        "# If a list, that list is assumed to contain stop words,\n",
        "# all of which will be removed from the resulting tokens.\n",
        "# Only applies if analyzer == 'word'.\n",
        "# If None, no stop words will be used. max_df can be set to a value in the range [0.7, 1.0)\n",
        "# to automatically detect and filter stop words based on intra corpus document frequency of terms.\n",
        "\n",
        "# token_pattern: str, default=r”(?u)\\b\\w\\w+\\b”\n",
        "# Regular expression denoting what constitutes a “token”, only used if analyzer == 'word'.\n",
        "# The default regexp select tokens of 2 or more alphanumeric characters\n",
        "# (punctuation is completely ignored and always treated as a token separator).\n",
        "# If there is a capturing group in token_pattern then the captured group content,\n",
        "# not the entire match, becomes the token. At most one capturing group is permitted.\n",
        "\n",
        "# ngram_range: tuple (min_n, max_n), default=(1, 1)\n",
        "# The lower and upper boundary of the range of n-values for different word n-grams\n",
        "# or char n-grams to be extracted.\n",
        "# All values of n such that min_n <= n <= max_n will be used.\n",
        "# For example an ngram_range of (1, 1) means only unigrams, (1, 2) means unigrams and bigrams,\n",
        "# and (2, 2) means only bigrams. Only applies if analyzer is not callable.\n",
        "\n",
        "# analyzer: {‘word’, ‘char’, ‘char_wb’} or callable, default=’word’\n",
        "# Whether the feature should be made of word n-gram or character n-grams.\n",
        "# Option ‘char_wb’ creates character n-grams only from text inside word boundaries;\n",
        "# n-grams at the edges of words are padded with space.\n",
        "# If a callable is passed it is used to extract the sequence of features out of the raw, unprocessed input.\n",
        "\n",
        "# Если 'word', то в словарь добавляются сочетания слов, количество слов задаётся в ngram_range.\n",
        "# Если 'char_wb', то в словарь добавляются сочетания символов, затрагивающие одно слово и пробелы вокруг слова,\n",
        "# количество символов в сочетаниях задаётся в ngram_range.\n",
        "# Если 'char', то то в словарь добавляются сочетания символов, в том числе затрагивающие несколько слов,\n",
        "# пробелы, знаки пунктуации.\n",
        "# Количество символов в сочетаниях задаётся в ngram_range.\n",
        "\n",
        "# max_df: float in range [0.0, 1.0] or int, default=1.0\n",
        "# When building the vocabulary ignore terms that have a document frequency strictly higher than\n",
        "# the given threshold (corpus-specific stop words).\n",
        "# If float, the parameter represents a proportion of documents, integer absolute counts.\n",
        "# This parameter is ignored if vocabulary is not None.\n",
        "\n",
        "# min_df: float in range [0.0, 1.0] or int, default=1\n",
        "# When building the vocabulary ignore terms that have a document frequency strictly lower than\n",
        "# the given threshold.\n",
        "# This value is also called cut-off in the literature.\n",
        "# If float, the parameter represents a proportion of documents, integer absolute counts.\n",
        "# This parameter is ignored if vocabulary is not None.\n",
        "\n",
        "# max_features: int, default=None\n",
        "# If not None, build a vocabulary that only consider the top max_features\n",
        "# ordered by term frequency across the corpus.\n",
        "# This parameter is ignored if vocabulary is not None.\n",
        "\n",
        "# vocabulary: Mapping or iterable, default=None\n",
        "# Either a Mapping (e.g., a dict) where keys are terms and values are indices in the feature matrix,\n",
        "# or an iterable over terms.\n",
        "# If not given, a vocabulary is determined from the input documents.\n",
        "# Indices in the mapping should not be repeated and should not have any gap between\n",
        "# 0 and the largest index.\n",
        "\n",
        "# binary: bool, default=False\n",
        "# If True, all non zero counts are set to 1. This is useful for discrete probabilistic models\n",
        "# that model binary events rather than integer counts.\n",
        "\n",
        "# dtype: type, default=np.int64\n",
        "# Type of the matrix returned by fit_transform() or transform().\n",
        "\n",
        "# При использовании конструктора по умолчанию объект  CountVectorizer удаляет пунктуацию,\n",
        "# односимвольные токены,  игнорирует регистр.\n",
        "\n",
        "\n",
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "# Create the Bag-of-Words\n",
        "bag_of_words = count_vectorizer.fit_transform(cat_imdb_df_2[\"Name\"])\n",
        "bag_of_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<6178x4919 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 15262 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lINQwEs3er8T",
        "outputId": "3a4e3569-d466-4ccf-a0d8-6fb309ebe034"
      },
      "source": [
        "# Как видим, результат получается в виде sparse matrix\n",
        "\n",
        "# Для преобразования в обычный ndarray\n",
        "bag_of_words.toarray()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1L0TNrergeQO",
        "outputId": "7214e944-07dc-49b3-bd82-a72902c4d45f"
      },
      "source": [
        "# Как видим, каждая из 6178 строк представлена в виде вектора длиной 4919\n",
        "# Здесь 4919 - размер словаря (уникальных слов), который определён на базе исходных строк\n",
        "bag_of_words.toarray().shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6178, 4919)"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c34PXTn3glcL",
        "outputId": "cd9ea661-19d3-4219-b6dc-49af1e606586"
      },
      "source": [
        "# Можно ограничить размер словаря, например, 1000 наиболее частотных слов\n",
        "\n",
        "count_vectorizer = CountVectorizer(max_features=1000)\n",
        "\n",
        "bag_of_words = count_vectorizer.fit_transform(cat_imdb_df_2[\"Name\"])\n",
        "bag_of_words.toarray().shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6178, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbjB6VYBiVt9",
        "outputId": "f34e2907-bea0-4088-feca-dd3ed5cc774f"
      },
      "source": [
        "# Можно создавать словарь из n-gram\n",
        "\n",
        "count_vectorizer = CountVectorizer(ngram_range=(5,5), analyzer='char_wb')\n",
        "\n",
        "bag_of_words = count_vectorizer.fit_transform(cat_imdb_df_2[\"Name\"])\n",
        "bag_of_words.toarray().shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6178, 16716)"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ginHyLa6mK_T",
        "outputId": "a4fa09cd-b96a-47ed-99c1-4de422b32d18"
      },
      "source": [
        "# Просмотр элементов словаря\n",
        "count_vectorizer.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' #sar',\n",
              " ' & ',\n",
              " \" '66 \",\n",
              " \" '70s\",\n",
              " \" '80s\",\n",
              " \" 'all\",\n",
              " \" 'bur\",\n",
              " \" 'em \",\n",
              " \" 'r \",\n",
              " ' (500',\n",
              " ' (fas',\n",
              " ' (fin',\n",
              " ' (fir',\n",
              " ' (ful',\n",
              " ' (ii)',\n",
              " ' (ish',\n",
              " ' (the',\n",
              " ' + ',\n",
              " ' - ',\n",
              " ' 1 ',\n",
              " ' 1/2 ',\n",
              " ' 10 ',\n",
              " ' 100 ',\n",
              " ' 1000',\n",
              " ' 101 ',\n",
              " ' 12 ',\n",
              " ' 12. ',\n",
              " ' 120 ',\n",
              " ' 127 ',\n",
              " ' 13 ',\n",
              " ' 13th',\n",
              " ' 1408',\n",
              " ' 16 ',\n",
              " ' 1666',\n",
              " ' 17 ',\n",
              " ' 1883',\n",
              " ' 19 ',\n",
              " ' 1917',\n",
              " ' 1922',\n",
              " ' 1978',\n",
              " ' 1984',\n",
              " ' 1992',\n",
              " ' 1994',\n",
              " ' 1: ',\n",
              " ' 2 ',\n",
              " ' 2, ',\n",
              " ' 20 ',\n",
              " ' 2000',\n",
              " ' 2001',\n",
              " ' 2010',\n",
              " ' 2012',\n",
              " ' 2049',\n",
              " ' 2067',\n",
              " ' 21 ',\n",
              " ' 22 ',\n",
              " ' 24 ',\n",
              " ' 25th',\n",
              " ' 26/1',\n",
              " ' 27 ',\n",
              " ' 28 ',\n",
              " ' 2: ',\n",
              " ' 2u ',\n",
              " ' 3 ',\n",
              " ' 3% ',\n",
              " ' 3-d ',\n",
              " ' 30 ',\n",
              " ' 300 ',\n",
              " ' 300:',\n",
              " ' 31 ',\n",
              " ' 355 ',\n",
              " ' 365 ',\n",
              " ' 37°2',\n",
              " ' 39 ',\n",
              " ' 3: ',\n",
              " ' 3:10',\n",
              " ' 3d ',\n",
              " ' 3dd ',\n",
              " ' 3rd ',\n",
              " ' 4 ',\n",
              " ' 40 ',\n",
              " ' 404 ',\n",
              " ' 414 ',\n",
              " ' 42 ',\n",
              " ' 43 ',\n",
              " ' 44 ',\n",
              " ' 4400',\n",
              " ' 47 ',\n",
              " ' 4: ',\n",
              " ' 5 ',\n",
              " ' 50 ',\n",
              " ' 5: ',\n",
              " ' 5th ',\n",
              " ' 6 ',\n",
              " ' 68 ',\n",
              " ' 7 ',\n",
              " ' 7th ',\n",
              " ' 8 ',\n",
              " ' 84 ',\n",
              " ' 86 ',\n",
              " ' 8mm ',\n",
              " ' 9 ',\n",
              " ' 9-1-',\n",
              " ' 9021',\n",
              " ' 911!',\n",
              " ' 93 ',\n",
              " ' 99 ',\n",
              " ' [rec',\n",
              " ' a ',\n",
              " ' a-te',\n",
              " ' a.i.',\n",
              " ' a.p.',\n",
              " ' abaj',\n",
              " ' abbe',\n",
              " ' abbo',\n",
              " ' abdu',\n",
              " ' abid',\n",
              " ' abis',\n",
              " ' abom',\n",
              " ' abou',\n",
              " ' abov',\n",
              " ' abra',\n",
              " ' abse',\n",
              " ' abys',\n",
              " ' acad',\n",
              " ' acap',\n",
              " ' acce',\n",
              " ' acci',\n",
              " ' acco',\n",
              " ' ace ',\n",
              " ' aces',\n",
              " ' acre',\n",
              " ' acro',\n",
              " ' act ',\n",
              " ' acti',\n",
              " ' actu',\n",
              " ' ad ',\n",
              " ' ada ',\n",
              " ' adal',\n",
              " ' adam',\n",
              " ' adap',\n",
              " ' add ',\n",
              " ' adda',\n",
              " ' adju',\n",
              " ' adri',\n",
              " ' adul',\n",
              " ' adve',\n",
              " ' advo',\n",
              " ' af ',\n",
              " ' affa',\n",
              " ' affæ',\n",
              " ' afra',\n",
              " ' afte',\n",
              " ' agai',\n",
              " ' agat',\n",
              " ' age ',\n",
              " ' age:',\n",
              " ' agen',\n",
              " ' ages',\n",
              " ' ah-g',\n",
              " ' ai ',\n",
              " ' aida',\n",
              " ' aile',\n",
              " ' ainb',\n",
              " ' air ',\n",
              " ' air/',\n",
              " ' airb',\n",
              " ' airp',\n",
              " ' ajeo',\n",
              " ' akad',\n",
              " ' akde',\n",
              " ' akes',\n",
              " ' akim',\n",
              " ' akin',\n",
              " ' akir',\n",
              " ' al ',\n",
              " ' alab',\n",
              " ' alad',\n",
              " ' alas',\n",
              " ' alex',\n",
              " ' alf ',\n",
              " ' alfr',\n",
              " ' algo',\n",
              " ' alia',\n",
              " ' alic',\n",
              " ' alie',\n",
              " ' alit',\n",
              " ' aliv',\n",
              " ' all ',\n",
              " ' all-',\n",
              " ' alle',\n",
              " ' alli',\n",
              " ' ally',\n",
              " ' alma',\n",
              " ' almi',\n",
              " ' almo',\n",
              " ' alon',\n",
              " ' alph',\n",
              " ' alpi',\n",
              " ' alte',\n",
              " ' alvi',\n",
              " ' alwa',\n",
              " ' am ',\n",
              " ' amad',\n",
              " ' amaz',\n",
              " ' ambu',\n",
              " ' amer',\n",
              " ' amig',\n",
              " ' amit',\n",
              " ' ammo',\n",
              " ' amon',\n",
              " ' amor',\n",
              " ' amph',\n",
              " ' amst',\n",
              " ' an ',\n",
              " ' anac',\n",
              " ' anar',\n",
              " ' anas',\n",
              " ' anat',\n",
              " ' anch',\n",
              " ' anci',\n",
              " ' and ',\n",
              " ' andh',\n",
              " ' andr',\n",
              " ' andy',\n",
              " ' ang-',\n",
              " ' ange',\n",
              " ' angr',\n",
              " ' anim',\n",
              " ' anna',\n",
              " ' anne',\n",
              " ' anni',\n",
              " ' anon',\n",
              " ' anot',\n",
              " ' ansa',\n",
              " ' ant-',\n",
              " ' anta',\n",
              " ' ante',\n",
              " ' anti',\n",
              " ' antl',\n",
              " ' anto',\n",
              " ' any ',\n",
              " ' anyt',\n",
              " ' apac',\n",
              " ' apar',\n",
              " ' aper',\n",
              " ' apes',\n",
              " ' apoc',\n",
              " ' apol',\n",
              " ' apos',\n",
              " ' appe',\n",
              " ' aqua',\n",
              " ' arab',\n",
              " ' arac',\n",
              " ' arca',\n",
              " ' arch',\n",
              " ' are ',\n",
              " ' argo',\n",
              " ' argy',\n",
              " ' ariz',\n",
              " ' ark ',\n",
              " ' arma',\n",
              " ' armi',\n",
              " ' army',\n",
              " ' arre',\n",
              " ' arri',\n",
              " ' arro',\n",
              " ' art ',\n",
              " ' arte',\n",
              " ' arth',\n",
              " ' arti',\n",
              " ' as ',\n",
              " ' asce',\n",
              " ' ash ',\n",
              " ' asia',\n",
              " ' ask ',\n",
              " ' aspi',\n",
              " ' assa',\n",
              " ' assi',\n",
              " ' aste',\n",
              " ' astr',\n",
              " ' at ',\n",
              " ' ater',\n",
              " ' atla',\n",
              " ' atom',\n",
              " ' aton',\n",
              " ' atta',\n",
              " ' atte',\n",
              " ' attr',\n",
              " ' atyp',\n",
              " ' auf ',\n",
              " ' augu',\n",
              " ' aunt',\n",
              " ' auro',\n",
              " ' aust',\n",
              " ' auto',\n",
              " ' ava ',\n",
              " ' avat',\n",
              " ' aven',\n",
              " ' avia',\n",
              " ' avp:',\n",
              " ' avpr',\n",
              " ' awak',\n",
              " ' away',\n",
              " ' awkw',\n",
              " ' axe ',\n",
              " ' axis',\n",
              " ' az ',\n",
              " ' azka',\n",
              " ' b ',\n",
              " ' baba',\n",
              " ' babe',\n",
              " ' baby',\n",
              " ' bac ',\n",
              " ' bach',\n",
              " ' back',\n",
              " ' bad ',\n",
              " ' bade',\n",
              " ' badl',\n",
              " ' baeg',\n",
              " ' bail',\n",
              " ' bake',\n",
              " ' baki',\n",
              " ' bal ',\n",
              " ' bala',\n",
              " ' ball',\n",
              " ' bam ',\n",
              " ' bana',\n",
              " ' band',\n",
              " ' bang',\n",
              " ' bank',\n",
              " ' banq',\n",
              " ' bans',\n",
              " ' bapt',\n",
              " ' bar ',\n",
              " ' barb',\n",
              " ' barc',\n",
              " ' barn',\n",
              " ' barr',\n",
              " ' base',\n",
              " ' basi',\n",
              " ' bask',\n",
              " ' bast',\n",
              " ' batc',\n",
              " ' bate',\n",
              " ' batm',\n",
              " ' bato',\n",
              " ' batt',\n",
              " ' batw',\n",
              " ' bay ',\n",
              " ' bayo',\n",
              " ' bayw',\n",
              " ' be ',\n",
              " ' beac',\n",
              " ' beal',\n",
              " ' bean',\n",
              " ' bear',\n",
              " ' beas',\n",
              " ' beau',\n",
              " ' beav',\n",
              " ' bebo',\n",
              " ' beck',\n",
              " ' beco',\n",
              " ' beda',\n",
              " ' bedr',\n",
              " ' bee ',\n",
              " ' been',\n",
              " ' bees',\n",
              " ' beet',\n",
              " ' befo',\n",
              " ' begi',\n",
              " ' begu',\n",
              " ' bein',\n",
              " ' bel-',\n",
              " ' belf',\n",
              " ' beli',\n",
              " ' belk',\n",
              " ' bell',\n",
              " ' belo',\n",
              " ' ben ',\n",
              " ' ben-',\n",
              " ' benc',\n",
              " ' bend',\n",
              " ' bene',\n",
              " ' beni',\n",
              " ' benj',\n",
              " ' beol',\n",
              " ' beon',\n",
              " ' beow',\n",
              " ' berg',\n",
              " ' berl',\n",
              " ' bern',\n",
              " ' bers',\n",
              " ' best',\n",
              " ' beta',\n",
              " ' bett',\n",
              " ' betw',\n",
              " ' beve',\n",
              " ' bewi',\n",
              " ' beyo',\n",
              " ' bfg ',\n",
              " ' bhoo',\n",
              " ' bhra',\n",
              " ' biba',\n",
              " ' big ',\n",
              " ' bill',\n",
              " ' bimi',\n",
              " ' bin ',\n",
              " ' bing',\n",
              " ' bins',\n",
              " ' bio ',\n",
              " ' bir ',\n",
              " ' bird',\n",
              " ' birt',\n",
              " ' bite',\n",
              " ' bitt',\n",
              " ' blac',\n",
              " ' blad',\n",
              " ' blai',\n",
              " ' blak',\n",
              " ' blan',\n",
              " ' blas',\n",
              " ' blaz',\n",
              " ' blea',\n",
              " ' blen',\n",
              " ' blin',\n",
              " ' blis',\n",
              " ' blit',\n",
              " ' blob',\n",
              " ' bloc',\n",
              " ' blon',\n",
              " ' bloo',\n",
              " ' blos',\n",
              " ' blow',\n",
              " ' blue',\n",
              " ' blus',\n",
              " ' blvd',\n",
              " ' bo ',\n",
              " ' bo-a',\n",
              " ' boar',\n",
              " ' boat',\n",
              " ' bob ',\n",
              " \" bob'\",\n",
              " ' bob?',\n",
              " ' boba',\n",
              " ' bobb',\n",
              " ' bodi',\n",
              " ' body',\n",
              " ' boga',\n",
              " ' bohe',\n",
              " ' boja',\n",
              " ' bojw',\n",
              " ' boku',\n",
              " ' bold',\n",
              " ' bole',\n",
              " ' bom ',\n",
              " ' bomb',\n",
              " ' bona',\n",
              " ' bone',\n",
              " ' bonn',\n",
              " ' boog',\n",
              " ' book',\n",
              " ' boom',\n",
              " ' boon',\n",
              " ' boot',\n",
              " ' bora',\n",
              " ' bord',\n",
              " ' borg',\n",
              " ' born',\n",
              " ' borr',\n",
              " ' boru',\n",
              " ' bosc',\n",
              " ' boss',\n",
              " ' bost',\n",
              " ' both',\n",
              " ' bott',\n",
              " ' boun',\n",
              " ' bour',\n",
              " ' bout',\n",
              " ' box ',\n",
              " ' boxi',\n",
              " ' boy ',\n",
              " ' boyh',\n",
              " ' boys',\n",
              " ' boyz',\n",
              " ' boît',\n",
              " ' brad',\n",
              " ' brai',\n",
              " ' braq',\n",
              " ' bras',\n",
              " ' brav',\n",
              " ' braw',\n",
              " ' braz',\n",
              " ' brea',\n",
              " ' bria',\n",
              " ' brib',\n",
              " ' brid',\n",
              " ' brig',\n",
              " ' brim',\n",
              " ' brin',\n",
              " ' brit',\n",
              " ' broa',\n",
              " ' broc',\n",
              " ' brok',\n",
              " ' bron',\n",
              " ' broo',\n",
              " ' bros',\n",
              " ' brot',\n",
              " ' brow',\n",
              " ' bruc',\n",
              " ' brug',\n",
              " ' brut',\n",
              " ' buck',\n",
              " ' bucl',\n",
              " ' bud ',\n",
              " ' buda',\n",
              " ' budd',\n",
              " ' buds',\n",
              " ' buel',\n",
              " ' buff',\n",
              " \" bug'\",\n",
              " ' bugs',\n",
              " ' buil',\n",
              " ' bul-',\n",
              " ' bull',\n",
              " ' bum ',\n",
              " ' bumb',\n",
              " ' bunc',\n",
              " ' bund',\n",
              " ' bunk',\n",
              " ' bunn',\n",
              " ' buon',\n",
              " ' bura',\n",
              " ' burd',\n",
              " ' bure',\n",
              " ' burg',\n",
              " ' buri',\n",
              " ' burl',\n",
              " ' burn',\n",
              " ' burî',\n",
              " ' burû',\n",
              " ' busa',\n",
              " ' busi',\n",
              " ' bust',\n",
              " ' but ',\n",
              " ' butc',\n",
              " ' butt',\n",
              " ' buy ',\n",
              " ' buye',\n",
              " ' buzz',\n",
              " ' by ',\n",
              " ' byul',\n",
              " ' bête',\n",
              " ' bôke',\n",
              " ' bôru',\n",
              " \" c'mo\",\n",
              " ' cabi',\n",
              " ' cabl',\n",
              " ' cabo',\n",
              " ' cadd',\n",
              " ' caes',\n",
              " ' cage',\n",
              " ' cake',\n",
              " ' cali',\n",
              " ' call',\n",
              " ' cam ',\n",
              " ' came',\n",
              " ' cami',\n",
              " ' camp',\n",
              " ' can ',\n",
              " \" can'\",\n",
              " ' canc',\n",
              " ' cand',\n",
              " ' cang',\n",
              " ' cann',\n",
              " ' cape',\n",
              " ' caph',\n",
              " ' capo',\n",
              " ' capt',\n",
              " ' cara',\n",
              " ' carb',\n",
              " ' card',\n",
              " ' care',\n",
              " ' cari',\n",
              " ' carl',\n",
              " ' carn',\n",
              " ' caro',\n",
              " ' carr',\n",
              " ' cars',\n",
              " ' cart',\n",
              " ' casa',\n",
              " ' case',\n",
              " ' cash',\n",
              " ' casi',\n",
              " ' casp',\n",
              " ' cass',\n",
              " ' cast',\n",
              " ' casu',\n",
              " ' cat ',\n",
              " \" cat'\",\n",
              " ' cata',\n",
              " ' catc',\n",
              " ' cats',\n",
              " ' catt',\n",
              " ' caus',\n",
              " ' cava',\n",
              " ' cave',\n",
              " ' cell',\n",
              " ' cens',\n",
              " ' cent',\n",
              " ' chac',\n",
              " ' chai',\n",
              " ' chal',\n",
              " ' cham',\n",
              " ' chan',\n",
              " ' chao',\n",
              " ' chap',\n",
              " ' char',\n",
              " ' chea',\n",
              " ' chee',\n",
              " ' chef',\n",
              " ' cheh',\n",
              " ' chem',\n",
              " ' cher',\n",
              " ' ches',\n",
              " ' chi ',\n",
              " ' chic',\n",
              " ' chih',\n",
              " ' chil',\n",
              " ' chin',\n",
              " ' chip',\n",
              " ' chit',\n",
              " ' cho ',\n",
              " ' choc',\n",
              " ' chos',\n",
              " ' chri',\n",
              " ' chro',\n",
              " ' chuc',\n",
              " ' chue',\n",
              " ' chug',\n",
              " ' chun',\n",
              " ' ci ',\n",
              " ' cida',\n",
              " ' cinc',\n",
              " ' cind',\n",
              " ' cine',\n",
              " ' circ',\n",
              " ' citi',\n",
              " ' citt',\n",
              " ' city',\n",
              " ' civi',\n",
              " ' clar',\n",
              " ' clas',\n",
              " ' clea',\n",
              " ' cleo',\n",
              " ' cler',\n",
              " ' clev',\n",
              " ' clic',\n",
              " ' clie',\n",
              " ' clif',\n",
              " ' clim',\n",
              " ' cliq',\n",
              " ' cloc',\n",
              " ' clon',\n",
              " ' clos',\n",
              " ' clou',\n",
              " ' clov',\n",
              " ' club',\n",
              " ' clue',\n",
              " ' clyd',\n",
              " ' coac',\n",
              " ' coal',\n",
              " ' coas',\n",
              " ' cobr',\n",
              " ' coci',\n",
              " ' cock',\n",
              " ' coco',\n",
              " ' coda',\n",
              " ' code',\n",
              " ' cody',\n",
              " ' cohe',\n",
              " ' cold',\n",
              " ' coll',\n",
              " ' colo',\n",
              " ' colu',\n",
              " ' come',\n",
              " ' comi',\n",
              " ' comm',\n",
              " ' comp',\n",
              " ' con ',\n",
              " ' cona',\n",
              " ' conc',\n",
              " ' cond',\n",
              " ' conf',\n",
              " ' cong',\n",
              " ' conj',\n",
              " ' conn',\n",
              " ' cons',\n",
              " ' cont',\n",
              " ' conv',\n",
              " ' cool',\n",
              " ' cop ',\n",
              " ' copp',\n",
              " ' cops',\n",
              " ' cora',\n",
              " ' core',\n",
              " ' corm',\n",
              " ' corn',\n",
              " ' coro',\n",
              " ' corp',\n",
              " ' cors',\n",
              " ' cosb',\n",
              " ' cosm',\n",
              " ' cost',\n",
              " ' così',\n",
              " ' coug',\n",
              " ' coul',\n",
              " ' coun',\n",
              " ' coup',\n",
              " ' cour',\n",
              " ' cous',\n",
              " ' cove',\n",
              " ' cow ',\n",
              " ' cowa',\n",
              " ' cowb',\n",
              " ' coyo',\n",
              " ' crad',\n",
              " ' craf',\n",
              " ' cran',\n",
              " ' cras',\n",
              " ' crav',\n",
              " ' craw',\n",
              " ' craz',\n",
              " ' crea',\n",
              " ' cree',\n",
              " ' cret',\n",
              " ' crim',\n",
              " ' cris',\n",
              " ' crit',\n",
              " ' croc',\n",
              " ' crof',\n",
              " ' croo',\n",
              " ' cros',\n",
              " ' crow',\n",
              " ' cruc',\n",
              " ' crue',\n",
              " ' crui',\n",
              " ' crus',\n",
              " ' cry ',\n",
              " ' cry-',\n",
              " ' cryi',\n",
              " ' cryp',\n",
              " ' crys',\n",
              " ' csi:',\n",
              " ' cu ',\n",
              " ' cube',\n",
              " ' cuck',\n",
              " ' cujo',\n",
              " ' cult',\n",
              " ' cups',\n",
              " ' curb',\n",
              " ' cure',\n",
              " ' curi',\n",
              " ' curs',\n",
              " ' cut ',\n",
              " ' cuts',\n",
              " ' cyra',\n",
              " ' cyst',\n",
              " ' d ',\n",
              " \" d'ad\",\n",
              " \" d'am\",\n",
              " ' d.p.',\n",
              " ' da ',\n",
              " ' dad ',\n",
              " ' dad!',\n",
              " ' dadd',\n",
              " ' dais',\n",
              " ' dale',\n",
              " ' dalk',\n",
              " ' dall',\n",
              " ' dalm',\n",
              " ' dalz',\n",
              " ' dama',\n",
              " ' dame',\n",
              " ' damn',\n",
              " ' danc',\n",
              " ' dang',\n",
              " ' dani',\n",
              " ' dant',\n",
              " ' dare',\n",
              " ' darj',\n",
              " ' dark',\n",
              " ' darl',\n",
              " ' das ',\n",
              " ' dasu',\n",
              " ' date',\n",
              " ' dati',\n",
              " ' daug',\n",
              " ' dave',\n",
              " ' davi',\n",
              " ' dawn',\n",
              " ' daws',\n",
              " ' day ',\n",
              " ' day:',\n",
              " ' dayb',\n",
              " ' dayl',\n",
              " ' days',\n",
              " ' daze',\n",
              " ' dc ',\n",
              " ' dci ',\n",
              " ' de ',\n",
              " ' dead',\n",
              " ' dear',\n",
              " ' deat',\n",
              " ' debr',\n",
              " ' dece',\n",
              " ' deck',\n",
              " ' deep',\n",
              " ' deer',\n",
              " ' defi',\n",
              " ' degr',\n",
              " ' dein',\n",
              " ' deja',\n",
              " ' del ',\n",
              " ' deli',\n",
              " ' delr',\n",
              " ' demo',\n",
              " ' den ',\n",
              " ' denk',\n",
              " ' denn',\n",
              " ' depa',\n",
              " ' der ',\n",
              " ' dern',\n",
              " ' derr',\n",
              " ' des ',\n",
              " ' desc',\n",
              " ' desi',\n",
              " ' deso',\n",
              " ' desp',\n",
              " ' dest',\n",
              " ' desu',\n",
              " ' det ',\n",
              " ' dete',\n",
              " ' deto',\n",
              " ' deuc',\n",
              " ' deus',\n",
              " ' deve',\n",
              " ' devi',\n",
              " ' dext',\n",
              " ' dhar',\n",
              " ' di ',\n",
              " ' diag',\n",
              " ' diam',\n",
              " ' dian',\n",
              " ' diar',\n",
              " ' dibl',\n",
              " ' dick',\n",
              " ' dict',\n",
              " ' did ',\n",
              " ' die ',\n",
              " ' dies',\n",
              " ' diet',\n",
              " ' diff',\n",
              " ' dig ',\n",
              " ' dinn',\n",
              " ' dino',\n",
              " ' dio ',\n",
              " ' dion',\n",
              " ' diri',\n",
              " ' dirk',\n",
              " ' dirt',\n",
              " ' disa',\n",
              " ' disc',\n",
              " ' dise',\n",
              " ' diso',\n",
              " ' disp',\n",
              " ' dist',\n",
              " ' dive',\n",
              " ' divi',\n",
              " ' dix ',\n",
              " ' dixi',\n",
              " ' djan',\n",
              " ' dni ',\n",
              " ' do ',\n",
              " ' do! ',\n",
              " ' do-g',\n",
              " ' doa:',\n",
              " ' doc ',\n",
              " ' doct',\n",
              " ' dodd',\n",
              " ' dodg',\n",
              " ' doe ',\n",
              " ' dog ',\n",
              " \" dog'\",\n",
              " ' dogm',\n",
              " ' dogs',\n",
              " ' dogv',\n",
              " ' dokk',\n",
              " ' doku',\n",
              " ' doli',\n",
              " ' doll',\n",
              " ' dolo',\n",
              " ' dome',\n",
              " ' domi',\n",
              " ' don ',\n",
              " \" don'\",\n",
              " ' donn',\n",
              " ' dono',\n",
              " ' doo,',\n",
              " ' doog',\n",
              " ' doom',\n",
              " ' door',\n",
              " ' dora',\n",
              " ' dori',\n",
              " ' dory',\n",
              " ' dou ',\n",
              " ' doub',\n",
              " ' down',\n",
              " ' doyl',\n",
              " ' doze',\n",
              " ' dr. ',\n",
              " ' drac',\n",
              " ' drag',\n",
              " ' drak',\n",
              " ' drea',\n",
              " ' dred',\n",
              " ' dres',\n",
              " ' drew',\n",
              " ' drif',\n",
              " ' drin',\n",
              " ' driv',\n",
              " ' dron',\n",
              " ' drop',\n",
              " ' drug',\n",
              " ' druk',\n",
              " ' drun',\n",
              " ' dry ',\n",
              " ' dræb',\n",
              " ' duba',\n",
              " ' dubl',\n",
              " ' duck',\n",
              " ' due ',\n",
              " ' duel',\n",
              " ' duff',\n",
              " ' dug ',\n",
              " ' duke',\n",
              " ' dumb',\n",
              " ' dump',\n",
              " ' dund',\n",
              " ' dune',\n",
              " ' dunk',\n",
              " ' dura',\n",
              " ' durh',\n",
              " ' durr',\n",
              " ' dusk',\n",
              " ' duty',\n",
              " ' dwar',\n",
              " ' dxd ',\n",
              " ' dyke',\n",
              " ' dyna',\n",
              " ' e ',\n",
              " ' e.t.',\n",
              " ' eagl',\n",
              " ' earl',\n",
              " ' earp',\n",
              " ' eart',\n",
              " ' east',\n",
              " ' easy',\n",
              " ' eat ',\n",
              " ' eati',\n",
              " ' ebbi',\n",
              " ' ecli',\n",
              " ' econ',\n",
              " ' ed ',\n",
              " ' eden',\n",
              " ' edge',\n",
              " ' educ',\n",
              " ' edwa',\n",
              " ' effe',\n",
              " ' effi',\n",
              " ' ego ',\n",
              " ' egyp',\n",
              " ' eiff',\n",
              " ' eigh',\n",
              " ' eine',\n",
              " ' ek ',\n",
              " ' el ',\n",
              " ' elec',\n",
              " ' eleg',\n",
              " ' elek',\n",
              " ' elem',\n",
              " ' elep',\n",
              " ' elev',\n",
              " ' elf ',\n",
              " ' eli ',\n",
              " ' eliz',\n",
              " ' ella',\n",
              " ' elle',\n",
              " ' elli',\n",
              " ' elm ',\n",
              " ' elmo',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZ5gHCHwmUGv",
        "outputId": "0b99dcb0-3277-40e2-e466-8019c31d6751"
      },
      "source": [
        "# Маппинг элементов словаря к их индексам в словаре (к их индексам в каждом выходном векторе фичи)\n",
        "count_vectorizer.vocabulary_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' no ': 2211,\n",
              " ' time': 3129,\n",
              " 'time ': 15227,\n",
              " ' to ': 3135,\n",
              " ' die ': 858,\n",
              " ' the ': 3100,\n",
              " ' guil': 1362,\n",
              " 'guilt': 8035,\n",
              " 'uilty': 15679,\n",
              " 'ilty ': 8924,\n",
              " ' many': 1959,\n",
              " 'many ': 10512,\n",
              " ' sain': 2699,\n",
              " 'saint': 14118,\n",
              " 'aints': 3995,\n",
              " 'ints ': 9137,\n",
              " ' of ': 2269,\n",
              " ' newa': 2196,\n",
              " 'newar': 11198,\n",
              " 'ewark': 7367,\n",
              " 'wark ': 16256,\n",
              " ' veno': 3290,\n",
              " 'venom': 16103,\n",
              " 'enom:': 6914,\n",
              " 'nom: ': 11442,\n",
              " ' let ': 1818,\n",
              " ' ther': 3106,\n",
              " 'there': 15142,\n",
              " 'here ': 8273,\n",
              " ' be ': 351,\n",
              " ' carn': 584,\n",
              " 'carna': 5387,\n",
              " 'arnag': 4569,\n",
              " 'rnage': 13737,\n",
              " 'nage ': 10966,\n",
              " ' dune': 948,\n",
              " 'dune ': 6306,\n",
              " ' ted ': 3079,\n",
              " ' lass': 1789,\n",
              " 'lasso': 9864,\n",
              " 'asso ': 4681,\n",
              " ' free': 1205,\n",
              " 'free ': 7640,\n",
              " ' guy ': 1371,\n",
              " ' hous': 1496,\n",
              " 'house': 8488,\n",
              " 'ouse ': 12489,\n",
              " ' drag': 921,\n",
              " 'drago': 6253,\n",
              " 'ragon': 13111,\n",
              " 'agon ': 3940,\n",
              " ' what': 3396,\n",
              " 'what ': 16319,\n",
              " ' if..': 1532,\n",
              " 'if...': 8775,\n",
              " 'f...?': 7428,\n",
              " '...? ': 3622,\n",
              " ' sex ': 2787,\n",
              " ' educ': 975,\n",
              " 'educa': 6545,\n",
              " 'ducat': 6290,\n",
              " 'ucati': 15590,\n",
              " 'catio': 5411,\n",
              " 'ation': 4758,\n",
              " 'tion ': 15247,\n",
              " ' walk': 3350,\n",
              " 'walki': 16233,\n",
              " 'alkin': 4113,\n",
              " 'lking': 10149,\n",
              " 'king ': 9662,\n",
              " ' dead': 810,\n",
              " 'dead ': 5972,\n",
              " ' ches': 623,\n",
              " 'chest': 5515,\n",
              " 'hestn': 8296,\n",
              " 'estnu': 7257,\n",
              " 'stnut': 14768,\n",
              " 'tnut ': 15303,\n",
              " ' man ': 1947,\n",
              " ' foun': 1191,\n",
              " 'found': 7621,\n",
              " 'ounda': 12458,\n",
              " 'undat': 15783,\n",
              " 'ndati': 11080,\n",
              " 'datio': 5938,\n",
              " ' sopr': 2929,\n",
              " 'sopra': 14583,\n",
              " 'opran': 12214,\n",
              " 'prano': 12943,\n",
              " 'ranos': 13173,\n",
              " 'anos ': 4363,\n",
              " ' only': 2291,\n",
              " 'only ': 12091,\n",
              " ' murd': 2142,\n",
              " 'murde': 10928,\n",
              " 'urder': 15900,\n",
              " 'rders': 13292,\n",
              " 'ders ': 6043,\n",
              " ' in ': 1548,\n",
              " ' buil': 521,\n",
              " 'build': 5279,\n",
              " 'uildi': 15674,\n",
              " 'ildin': 8872,\n",
              " 'lding': 9916,\n",
              " 'ding ': 6128,\n",
              " ' amer': 205,\n",
              " 'ameri': 4198,\n",
              " 'meric': 10661,\n",
              " 'erica': 7108,\n",
              " 'rican': 13559,\n",
              " 'ican ': 8644,\n",
              " ' horr': 1487,\n",
              " 'horro': 8463,\n",
              " 'orror': 12316,\n",
              " 'rror ': 13930,\n",
              " ' stor': 2989,\n",
              " 'story': 14781,\n",
              " 'tory ': 15361,\n",
              " ' sein': 2763,\n",
              " 'seinf': 14233,\n",
              " 'einfe': 6651,\n",
              " 'infel': 9041,\n",
              " 'nfeld': 11211,\n",
              " 'feld ': 7489,\n",
              " ' grey': 1342,\n",
              " \"grey'\": 7994,\n",
              " \"rey's\": 13494,\n",
              " \"ey's \": 7411,\n",
              " ' anat': 217,\n",
              " 'anato': 4249,\n",
              " 'natom': 11015,\n",
              " 'atomy': 4769,\n",
              " 'tomy ': 15332,\n",
              " ' game': 1244,\n",
              " 'game ': 7717,\n",
              " ' thro': 3118,\n",
              " 'thron': 15180,\n",
              " 'hrone': 8510,\n",
              " 'rones': 13818,\n",
              " 'ones ': 12050,\n",
              " ' blac': 415,\n",
              " 'black': 5108,\n",
              " 'lack ': 9796,\n",
              " ' wido': 3412,\n",
              " 'widow': 16343,\n",
              " 'idow ': 8735,\n",
              " ' last': 1790,\n",
              " 'last ': 9865,\n",
              " ' duel': 941,\n",
              " 'duel ': 6295,\n",
              " ' alic': 183,\n",
              " 'alice': 4097,\n",
              " 'lice ': 10043,\n",
              " ' bord': 465,\n",
              " 'borde': 5183,\n",
              " 'order': 12240,\n",
              " 'rderl': 13291,\n",
              " 'derla': 6036,\n",
              " 'erlan': 7123,\n",
              " 'rland': 13695,\n",
              " 'land ': 9832,\n",
              " ' shan': 2801,\n",
              " 'shang': 14316,\n",
              " 'hang-': 8140,\n",
              " 'ang-c': 4295,\n",
              " 'ng-ch': 11222,\n",
              " 'g-chi': 7693,\n",
              " '-chi ': 3576,\n",
              " ' and ': 220,\n",
              " ' lege': 1810,\n",
              " 'legen': 9957,\n",
              " 'egend': 6611,\n",
              " 'gend ': 7781,\n",
              " ' ten ': 3087,\n",
              " ' ring': 2628,\n",
              " 'rings': 13625,\n",
              " 'ings ': 9066,\n",
              " ' bill': 404,\n",
              " 'billi': 5087,\n",
              " 'illio': 8905,\n",
              " 'llion': 10201,\n",
              " 'lions': 10109,\n",
              " 'ions ': 9168,\n",
              " ' resi': 2599,\n",
              " 'resid': 13457,\n",
              " 'eside': 7221,\n",
              " 'siden': 14405,\n",
              " 'ident': 8707,\n",
              " 'dent ': 6016,\n",
              " ' evil': 1056,\n",
              " 'evil:': 7360,\n",
              " 'vil: ': 16161,\n",
              " ' welc': 3388,\n",
              " 'welco': 16300,\n",
              " 'elcom': 6680,\n",
              " 'lcome': 9900,\n",
              " 'come ': 5705,\n",
              " ' racc': 2530,\n",
              " 'racco': 13077,\n",
              " 'accoo': 3753,\n",
              " 'ccoon': 5424,\n",
              " 'coon ': 5740,\n",
              " ' city': 648,\n",
              " 'city ': 5603,\n",
              " ' spec': 2945,\n",
              " 'spect': 14606,\n",
              " 'pectr': 12684,\n",
              " 'ectre': 6506,\n",
              " 'ctre ': 5850,\n",
              " ' casi': 592,\n",
              " 'casin': 5399,\n",
              " 'asino': 4653,\n",
              " 'sino ': 14437,\n",
              " ' roya': 2665,\n",
              " 'royal': 13890,\n",
              " 'oyale': 12573,\n",
              " 'yale ': 16498,\n",
              " ' luci': 1889,\n",
              " 'lucif': 10356,\n",
              " 'ucife': 15598,\n",
              " 'cifer': 5577,\n",
              " 'ifer ': 8778,\n",
              " ' morn': 2104,\n",
              " 'morni': 10846,\n",
              " 'ornin': 12296,\n",
              " 'rning': 13756,\n",
              " 'ning ': 11338,\n",
              " ' show': 2830,\n",
              " 'show ': 14376,\n",
              " ' hall': 1397,\n",
              " 'hallo': 8120,\n",
              " 'allow': 4135,\n",
              " 'llowe': 10213,\n",
              " 'lowee': 10317,\n",
              " 'oween': 12539,\n",
              " 'ween ': 16292,\n",
              " ' kill': 1715,\n",
              " 'kills': 9651,\n",
              " 'ills ': 8910,\n",
              " \"here'\": 8274,\n",
              " \"ere's\": 7067,\n",
              " \"re's \": 13310,\n",
              " ' some': 2922,\n",
              " 'someo': 14564,\n",
              " 'omeon': 11981,\n",
              " 'meone': 10655,\n",
              " 'eone ': 6971,\n",
              " ' insi': 1568,\n",
              " 'insid': 9115,\n",
              " 'nside': 11526,\n",
              " 'side ': 14404,\n",
              " ' your': 3495,\n",
              " 'your ': 16581,\n",
              " ' mali': 1938,\n",
              " 'malig': 10472,\n",
              " 'align': 4101,\n",
              " 'ligna': 10081,\n",
              " 'ignan': 8836,\n",
              " 'gnant': 7912,\n",
              " 'nant ': 10988,\n",
              " ' wolf': 3433,\n",
              " 'wolf ': 16395,\n",
              " ' la ': 1769,\n",
              " ' casa': 589,\n",
              " 'casa ': 5394,\n",
              " ' de ': 809,\n",
              " ' pape': 2351,\n",
              " 'papel': 12621,\n",
              " 'apel ': 4419,\n",
              " ' tick': 3121,\n",
              " 'tick,': 15200,\n",
              " 'ick, ': 8668,\n",
              " 'tick.': 15201,\n",
              " 'ick..': 8670,\n",
              " 'ck...': 5610,\n",
              " 'k... ': 9555,\n",
              " ' boom': 461,\n",
              " 'boom!': 5177,\n",
              " 'oom! ': 12161,\n",
              " ' nigh': 2202,\n",
              " 'night': 11326,\n",
              " 'ight ': 8817,\n",
              " ' succ': 3000,\n",
              " 'succe': 14817,\n",
              " 'ucces': 15591,\n",
              " 'ccess': 5421,\n",
              " 'cessi': 5461,\n",
              " 'essio': 7242,\n",
              " 'ssion': 14677,\n",
              " 'sion ': 14440,\n",
              " ' brea': 492,\n",
              " 'brea ': 5225,\n",
              " 'enom ': 6913,\n",
              " ' skyf': 2874,\n",
              " 'skyfa': 14484,\n",
              " 'kyfal': 9765,\n",
              " 'yfall': 16536,\n",
              " 'fall ': 7445,\n",
              " ' ncis': 2181,\n",
              " 'ncis:': 11060,\n",
              " 'cis: ': 5595,\n",
              " ' nava': 2180,\n",
              " 'naval': 11020,\n",
              " 'aval ': 4835,\n",
              " ' crim': 735,\n",
              " 'crimi': 5807,\n",
              " 'rimin': 13610,\n",
              " 'imina': 8951,\n",
              " 'minal': 10724,\n",
              " 'inal ': 8976,\n",
              " ' inve': 1577,\n",
              " 'inves': 9146,\n",
              " 'nvest': 11662,\n",
              " 'vesti': 16140,\n",
              " 'estig': 7253,\n",
              " 'stiga': 14748,\n",
              " 'tigat': 15217,\n",
              " 'igati': 8806,\n",
              " 'gativ': 7744,\n",
              " 'ative': 4759,\n",
              " 'tive ': 15264,\n",
              " ' serv': 2780,\n",
              " 'servi': 14271,\n",
              " 'ervic': 7196,\n",
              " 'rvice': 14059,\n",
              " 'vice ': 16143,\n",
              " ' see ': 2755,\n",
              " ' adda': 141,\n",
              " 'addam': 3830,\n",
              " 'ddams': 5958,\n",
              " 'dams ': 5913,\n",
              " ' fami': 1095,\n",
              " 'famil': 7452,\n",
              " 'amily': 4209,\n",
              " 'mily ': 10720,\n",
              " ' 2 ': 44,\n",
              " ' big ': 403,\n",
              " ' sky ': 2873,\n",
              " ' peak': 2371,\n",
              " 'peaky': 12672,\n",
              " 'eaky ': 6381,\n",
              " ' blin': 424,\n",
              " 'blind': 5127,\n",
              " 'linde': 10093,\n",
              " 'inder': 9012,\n",
              " 'nders': 11103,\n",
              " ' we ': 3377,\n",
              " ' do ': 882,\n",
              " ' shad': 2795,\n",
              " 'shado': 14309,\n",
              " 'hadow': 8093,\n",
              " 'adows': 3870,\n",
              " 'dows ': 6245,\n",
              " ' tita': 3134,\n",
              " 'titan': 15257,\n",
              " 'itane': 9340,\n",
              " 'tane ': 14937,\n",
              " 'crime': 5806,\n",
              " 'rime ': 13607,\n",
              " ' csi:': 752,\n",
              " 'csi: ': 5832,\n",
              " ' vega': 3285,\n",
              " 'vegas': 16080,\n",
              " 'egas ': 6610,\n",
              " ' stra': 2991,\n",
              " 'stran': 14788,\n",
              " 'trang': 15394,\n",
              " 'range': 13165,\n",
              " 'anger': 4304,\n",
              " 'nger ': 11249,\n",
              " ' thin': 3110,\n",
              " 'thing': 15157,\n",
              " 'hings': 8357,\n",
              " 'itans': 9343,\n",
              " 'tans ': 14946,\n",
              " ' goli': 1313,\n",
              " 'golia': 7944,\n",
              " 'oliat': 11902,\n",
              " 'liath': 10037,\n",
              " 'iath ': 8619,\n",
              " 'break': 5227,\n",
              " 'reaki': 13326,\n",
              " 'eakin': 6378,\n",
              " 'aking': 4051,\n",
              " ' bad ': 315,\n",
              " ' on ': 2287,\n",
              " ' my ': 2150,\n",
              " ' bloc': 428,\n",
              " 'block': 5132,\n",
              " 'lock ': 10246,\n",
              " ' old ': 2278,\n",
              " ' y: ': 3475,\n",
              " ' rook': 2653,\n",
              " 'rooki': 13834,\n",
              " 'ookie': 12153,\n",
              " 'okie ': 11857,\n",
              " ' one ': 2289,\n",
              " ' gets': 1270,\n",
              " 'gets ': 7808,\n",
              " ' out ': 2320,\n",
              " ' aliv': 186,\n",
              " 'alive': 4110,\n",
              " 'live ': 10136,\n",
              " ' law ': 1794,\n",
              " ' & ': 1,\n",
              " ' orde': 2303,\n",
              " 'rder:': 13289,\n",
              " 'der: ': 6027,\n",
              " 'speci': 14605,\n",
              " 'pecia': 12678,\n",
              " 'ecial': 6480,\n",
              " 'cial ': 5564,\n",
              " ' vict': 3303,\n",
              " 'victi': 16146,\n",
              " 'ictim': 8684,\n",
              " 'ctims': 5840,\n",
              " 'tims ': 15232,\n",
              " ' unit': 3245,\n",
              " 'unit ': 15815,\n",
              " ' hocu': 1465,\n",
              " 'hocus': 8409,\n",
              " 'ocus ': 11760,\n",
              " ' pocu': 2435,\n",
              " 'pocus': 12857,\n",
              " ' offi': 2271,\n",
              " 'offic': 11800,\n",
              " 'ffice': 7520,\n",
              " 'fice ': 7531,\n",
              " ' chic': 625,\n",
              " 'chica': 5520,\n",
              " 'hicag': 8306,\n",
              " 'icago': 8641,\n",
              " 'cago ': 5337,\n",
              " ' fire': 1150,\n",
              " 'fire ': 7561,\n",
              " ' you ': 3491,\n",
              " ' den ': 826,\n",
              " ' skyl': 2875,\n",
              " 'skyld': 14485,\n",
              " 'kyldi': 9766,\n",
              " 'yldig': 16546,\n",
              " 'ldige': 9915,\n",
              " 'dige ': 6121,\n",
              " ' quan': 2519,\n",
              " 'quant': 13040,\n",
              " 'uantu': 15568,\n",
              " 'antum': 4407,\n",
              " 'ntum ': 11640,\n",
              " ' sola': 2916,\n",
              " 'solac': 14552,\n",
              " 'olace': 11872,\n",
              " 'lace ': 9792,\n",
              " ' doom': 909,\n",
              " 'doom ': 6224,\n",
              " ' patr': 2365,\n",
              " 'patro': 12660,\n",
              " 'atrol': 4783,\n",
              " 'trol ': 15433,\n",
              " ' yell': 3481,\n",
              " 'yello': 16521,\n",
              " 'ellow': 6730,\n",
              " 'llows': 10215,\n",
              " 'lowst': 10324,\n",
              " 'owsto': 12563,\n",
              " 'wston': 16441,\n",
              " 'stone': 14773,\n",
              " 'tone ': 15334,\n",
              " ' suic': 3006,\n",
              " 'suici': 14823,\n",
              " 'uicid': 15667,\n",
              " 'icide': 8664,\n",
              " 'cide ': 5569,\n",
              " ' squa': 2963,\n",
              " 'squad': 14640,\n",
              " 'quad ': 13035,\n",
              " ' frie': 1209,\n",
              " 'frien': 7647,\n",
              " 'riend': 13581,\n",
              " 'iends': 8755,\n",
              " 'ends ': 6852,\n",
              " ' eter': 1046,\n",
              " 'etern': 7277,\n",
              " 'terna': 15088,\n",
              " 'ernal': 7137,\n",
              " 'rnals': 13739,\n",
              " 'nals ': 10977,\n",
              " ' broo': 504,\n",
              " 'brook': 5251,\n",
              " 'rookl': 13835,\n",
              " 'ookly': 12155,\n",
              " 'oklyn': 11862,\n",
              " 'klyn ': 9696,\n",
              " ' nine': 2206,\n",
              " 'nine-': 11336,\n",
              " 'ine-n': 9025,\n",
              " 'ne-ni': 11152,\n",
              " 'e-nin': 6343,\n",
              " '-nine': 3604,\n",
              " 'nine ': 11335,\n",
              " ' crue': 744,\n",
              " 'cruel': 5823,\n",
              " 'ruell': 14016,\n",
              " 'uella': 15628,\n",
              " 'ella ': 6714,\n",
              " 'lackl': 9801,\n",
              " 'ackli': 3793,\n",
              " 'cklis': 5628,\n",
              " 'klist': 9693,\n",
              " 'list ': 10121,\n",
              " ' supe': 3018,\n",
              " 'super': 14837,\n",
              " 'upern': 15870,\n",
              " 'perna': 12732,\n",
              " 'ernat': 7138,\n",
              " 'rnatu': 13744,\n",
              " 'natur': 11019,\n",
              " 'atura': 4797,\n",
              " 'tural': 15511,\n",
              " 'ural ': 15888,\n",
              " ' down': 916,\n",
              " 'downt': 6243,\n",
              " 'ownto': 12556,\n",
              " 'wnton': 16393,\n",
              " 'nton ': 11627,\n",
              " ' abbe': 112,\n",
              " 'abbey': 3712,\n",
              " 'bbey ': 4989,\n",
              " ' anim': 227,\n",
              " 'anima': 4330,\n",
              " 'nimal': 11332,\n",
              " 'imal ': 8931,\n",
              " ' king': 1723,\n",
              " 'kingd': 9666,\n",
              " 'ingdo': 9052,\n",
              " 'ngdom': 11234,\n",
              " 'gdom ': 7752,\n",
              " ' mind': 2067,\n",
              " 'minds': 10731,\n",
              " 'inds ': 9019,\n",
              " ' vigi': 3307,\n",
              " 'vigil': 16155,\n",
              " 'igil ': 8831,\n",
              " ' infi': 1558,\n",
              " 'infin': 9043,\n",
              " 'nfini': 11214,\n",
              " 'finit': 7560,\n",
              " 'inite': 9083,\n",
              " 'nite ': 11357,\n",
              " ' v/h/': 3270,\n",
              " 'v/h/s': 16045,\n",
              " '/h/s/': 3641,\n",
              " 'h/s/9': 8079,\n",
              " '/s/94': 3649,\n",
              " 's/94 ': 14098,\n",
              " ' good': 1317,\n",
              " 'good ': 7950,\n",
              " ' doct': 887,\n",
              " 'docto': 6193,\n",
              " 'octor': 11756,\n",
              " 'ctor ': 5846,\n",
              " ' dext': 847,\n",
              " 'dexte': 6071,\n",
              " 'exter': 7407,\n",
              " 'xter ': 16478,\n",
              " ' gree': 1338,\n",
              " 'green': 7988,\n",
              " 'reen ': 13383,\n",
              " ' knig': 1732,\n",
              " 'knigh': 9700,\n",
              " 'down ': 6241,\n",
              " ' fren': 1206,\n",
              " 'frenc': 7643,\n",
              " 'rench': 13431,\n",
              " 'ench ': 6827,\n",
              " ' disp': 874,\n",
              " 'dispa': 6154,\n",
              " 'ispat': 9296,\n",
              " 'spatc': 14602,\n",
              " 'patch': 12652,\n",
              " 'atch ': 4714,\n",
              " ' boys': 482,\n",
              " 'boys ': 5210,\n",
              " ' ridl': 2621,\n",
              " 'ridle': 13577,\n",
              " 'idley': 8731,\n",
              " 'dley ': 6175,\n",
              " ' road': 2639,\n",
              " 'road ': 13766,\n",
              " ' viki': 3311,\n",
              " 'vikin': 16159,\n",
              " 'iking': 8861,\n",
              " 'kings': 9670,\n",
              " ' spid': 2949,\n",
              " 'spide': 14618,\n",
              " 'pider': 12787,\n",
              " 'ider-': 8712,\n",
              " 'der-m': 6025,\n",
              " 'er-ma': 7024,\n",
              " 'r-man': 13062,\n",
              " '-man:': 3601,\n",
              " 'man: ': 10486,\n",
              " ' way ': 3373,\n",
              " ' home': 1473,\n",
              " 'home ': 8431,\n",
              " ' sile': 2847,\n",
              " 'silen': 14418,\n",
              " 'ilent': 8879,\n",
              " 'lent ': 9976,\n",
              " ' witn': 3427,\n",
              " 'witne': 16377,\n",
              " 'itnes': 9383,\n",
              " 'tness': 15300,\n",
              " 'ness ': 11189,\n",
              " ' ghos': 1273,\n",
              " 'ghost': 7825,\n",
              " 'hosts': 8477,\n",
              " 'osts ': 12394,\n",
              " ' card': 580,\n",
              " 'card ': 5374,\n",
              " ' coun': 716,\n",
              " 'count': 5768,\n",
              " 'ounte': 12470,\n",
              " 'unter': 15847,\n",
              " 'nter ': 11584,\n",
              " ' lamb': 1778,\n",
              " 'lamb ': 9823,\n",
              " ' mids': 2055,\n",
              " 'midso': 10700,\n",
              " 'idsom': 8737,\n",
              " 'dsome': 6282,\n",
              " 'somer': 14565,\n",
              " 'omer ': 11982,\n",
              " ' rick': 2616,\n",
              " 'rick ': 13563,\n",
              " ' mort': 2107,\n",
              " 'morty': 10855,\n",
              " 'orty ': 12337,\n",
              " ' afte': 151,\n",
              " 'after': 3907,\n",
              " 'fter ': 7659,\n",
              " ' fell': 1124,\n",
              " 'fell ': 7491,\n",
              " ' rive': 2636,\n",
              " 'river': 13674,\n",
              " 'iverd': 9418,\n",
              " 'verda': 16116,\n",
              " 'erdal': 7057,\n",
              " 'rdale': 13276,\n",
              " 'dale ': 5900,\n",
              " ' hard': 1410,\n",
              " 'harde': 8170,\n",
              " 'arder': 4492,\n",
              " 'rder ': 13287,\n",
              " ' they': 3107,\n",
              " 'they ': 15150,\n",
              " ' fall': 1093,\n",
              " ' lico': 1830,\n",
              " 'licor': 10051,\n",
              " 'icori': 8682,\n",
              " 'coric': 5748,\n",
              " 'orice': 12266,\n",
              " 'rice ': 13560,\n",
              " ' pizz': 2424,\n",
              " 'pizza': 12824,\n",
              " 'izza ': 9450,\n",
              " ' med ': 2019,\n",
              " ' lost': 1878,\n",
              " 'lost ': 10294,\n",
              " ' symb': 3037,\n",
              " 'symbo': 14865,\n",
              " 'ymbol': 16556,\n",
              " 'mbol ': 10598,\n",
              " ' star': 2972,\n",
              " 'star ': 14707,\n",
              " ' wars': 3366,\n",
              " 'wars:': 16263,\n",
              " 'ars: ': 4596,\n",
              " ' visi': 3322,\n",
              " 'visio': 16180,\n",
              " 'ision': 9280,\n",
              " 'sions': 14444,\n",
              " ' prom': 2492,\n",
              " 'promi': 12980,\n",
              " 'romis': 13810,\n",
              " 'omisi': 11998,\n",
              " 'misin': 10758,\n",
              " 'ising': 9279,\n",
              " 'sing ': 14430,\n",
              " ' youn': 3494,\n",
              " 'young': 16580,\n",
              " 'oung ': 12463,\n",
              " ' woma': 3435,\n",
              " 'woman': 16400,\n",
              " 'oman ': 11958,\n",
              " ' mode': 2087,\n",
              " 'moder': 10804,\n",
              " 'odern': 11769,\n",
              " 'dern ': 6039,\n",
              " ' mand': 1952,\n",
              " 'manda': 10491,\n",
              " 'andal': 4268,\n",
              " 'ndalo': 11075,\n",
              " 'dalor': 5905,\n",
              " 'alori': 4151,\n",
              " 'loria': 10285,\n",
              " 'orian': 12265,\n",
              " 'rian ': 13547,\n",
              " ' quee': 2521,\n",
              " 'queen': 13043,\n",
              " 'ueenp': 15624,\n",
              " 'eenpi': 6566,\n",
              " 'enpin': 6916,\n",
              " 'npins': 11490,\n",
              " 'pins ': 12806,\n",
              " ' bang': 328,\n",
              " 'bang ': 4951,\n",
              " ' theo': 3105,\n",
              " 'theor': 15136,\n",
              " 'heory': 8265,\n",
              " 'eory ': 6981,\n",
              " ' wire': 3423,\n",
              " 'wire ': 16366,\n",
              " ' who ': 3405,\n",
              " ' cand': 571,\n",
              " 'candy': 5357,\n",
              " 'andym': 4286,\n",
              " 'ndyma': 11149,\n",
              " 'dyman': 6328,\n",
              " 'yman ': 16555,\n",
              " ' whit': 3404,\n",
              " 'white': 16331,\n",
              " 'hite ': 8379,\n",
              " ' lotu': 1880,\n",
              " 'lotus': 10297,\n",
              " 'otus ': 12431,\n",
              " ' witc': 3425,\n",
              " 'witch': 16373,\n",
              " 'itche': 9350,\n",
              " 'tcher': 15003,\n",
              " 'cher ': 5507,\n",
              " 'starl': 14710,\n",
              " 'tarli': 14959,\n",
              " 'arlin': 4558,\n",
              " 'rling': 13711,\n",
              " 'ling ': 10098,\n",
              " ' kate': 1697,\n",
              " 'kate ': 9588,\n",
              " ' sand': 2710,\n",
              " 'sandm': 14133,\n",
              " 'andma': 4277,\n",
              " 'ndman': 11130,\n",
              " 'dman ': 6181,\n",
              " ' kniv': 1733,\n",
              " 'knive': 9701,\n",
              " 'nives': 11367,\n",
              " 'ives ': 9422,\n",
              " ' new ': 2194,\n",
              " ' amst': 212,\n",
              " 'amste': 4235,\n",
              " 'mster': 10906,\n",
              " 'sterd': 14732,\n",
              " 'terda': 15069,\n",
              " 'erdam': 7058,\n",
              " 'rdam ': 13277,\n",
              " ' cry ': 747,\n",
              " ' mach': 1915,\n",
              " 'macho': 10433,\n",
              " 'acho ': 3776,\n",
              " ' cast': 595,\n",
              " 'castl': 5405,\n",
              " 'astle': 4690,\n",
              " 'stle ': 14761,\n",
              " ' mirr': 2075,\n",
              " 'mirro': 10750,\n",
              " 'irror': 9239,\n",
              " ' orga': 2306,\n",
              " 'organ': 12254,\n",
              " 'rgani': 13507,\n",
              " 'ganiz': 7728,\n",
              " 'anize': 4333,\n",
              " 'nized': 11370,\n",
              " 'ized ': 9442,\n",
              " ' till': 3127,\n",
              " 'till ': 15224,\n",
              " ' deat': 812,\n",
              " 'death': 5980,\n",
              " 'eath ': 6435,\n",
              " ' voye': 3334,\n",
              " 'voyeu': 16206,\n",
              " 'oyeur': 12576,\n",
              " 'yeurs': 16535,\n",
              " 'eurs ': 7335,\n",
              " ' crow': 742,\n",
              " 'crown': 5820,\n",
              " 'rown ': 13886,\n",
              " ' bett': 394,\n",
              " 'bette': 5067,\n",
              " 'etter': 7305,\n",
              " 'tter ': 15474,\n",
              " ' call': 563,\n",
              " 'call ': 5344,\n",
              " ' saul': 2718,\n",
              " 'saul ': 14157,\n",
              " ' hand': 1402,\n",
              " 'handm': 8137,\n",
              " 'ndmai': 11129,\n",
              " 'dmaid': 6180,\n",
              " \"maid'\": 10459,\n",
              " \"aid's\": 3961,\n",
              " \"id's \": 8692,\n",
              " ' tale': 3057,\n",
              " 'tale ': 14912,\n",
              " ' outl': 2323,\n",
              " 'outla': 12499,\n",
              " 'utlan': 16016,\n",
              " 'tland': 15270,\n",
              " 'lande': 9834,\n",
              " 'ander': 4270,\n",
              " 'nder ': 11092,\n",
              " ' simp': 2853,\n",
              " 'simps': 14425,\n",
              " 'impso': 8966,\n",
              " 'mpson': 10896,\n",
              " 'psons': 12997,\n",
              " 'sons ': 14581,\n",
              " ' dear': 811,\n",
              " 'dear ': 5979,\n",
              " ' evan': 1052,\n",
              " 'evan ': 7339,\n",
              " ' hans': 1406,\n",
              " 'hanse': 8152,\n",
              " 'ansen': 4373,\n",
              " 'nsen ': 11512,\n",
              " ' scen': 2728,\n",
              " 'scene': 14179,\n",
              " 'cene ': 5444,\n",
              " 'gatio': 7743,\n",
              " ' loki': 1864,\n",
              " 'loki ': 10256,\n",
              " \" it's\": 1593,\n",
              " \"it's \": 9330,\n",
              " ' alwa': 200,\n",
              " 'alway': 4166,\n",
              " 'lways': 10398,\n",
              " 'ways ': 16277,\n",
              " ' sunn': 3015,\n",
              " 'sunny': 14833,\n",
              " 'unny ': 15830,\n",
              " ' phil': 2399,\n",
              " 'phila': 12763,\n",
              " 'hilad': 8330,\n",
              " 'ilade': 8866,\n",
              " 'ladel': 9808,\n",
              " 'adelp': 3841,\n",
              " 'delph': 5999,\n",
              " 'elphi': 6749,\n",
              " 'lphia': 10326,\n",
              " 'phia ': 12761,\n",
              " ' hypn': 1516,\n",
              " 'hypno': 8578,\n",
              " 'ypnot': 16584,\n",
              " 'pnoti': 12854,\n",
              " 'notic': 11473,\n",
              " 'otic ': 12410,\n",
              " 'upers': 15871,\n",
              " 'perst': 12742,\n",
              " 'ersto': 7186,\n",
              " 'rstor': 13966,\n",
              " 'store': 14778,\n",
              " 'tore ': 15349,\n",
              " ' gisa': 1289,\n",
              " 'gisae': 7885,\n",
              " 'isaen': 9249,\n",
              " 'saeng': 14108,\n",
              " 'aengc': 3891,\n",
              " 'engch': 6873,\n",
              " 'ngchu': 11233,\n",
              " 'gchun': 7751,\n",
              " 'chung': 5559,\n",
              " 'hung ': 8550,\n",
              " ' mr. ': 2122,\n",
              " ' robo': 2642,\n",
              " 'robot': 13773,\n",
              " 'obot ': 11712,\n",
              " ' soho': 2915,\n",
              " 'soho ': 14550,\n",
              " 'itani': 9341,\n",
              " 'tanic': 14944,\n",
              " 'anic ': 4327,\n",
              " ' shid': 2815,\n",
              " 'shidd': 14345,\n",
              " 'hidda': 8314,\n",
              " 'iddat': 8699,\n",
              " 'ddat ': 5959,\n",
              " ' scre': 2740,\n",
              " 'screa': 14201,\n",
              " 'cream': 5793,\n",
              " 'ream ': 13333,\n",
              " ' ozar': 2334,\n",
              " 'ozark': 12583,\n",
              " 'zark ': 16638,\n",
              " ' rise': 2631,\n",
              " 'rise ': 13643,\n",
              " ' foot': 1179,\n",
              " 'foots': 7601,\n",
              " 'ootso': 12187,\n",
              " 'otsol': 12423,\n",
              " 'tsold': 15460,\n",
              " 'soldi': 14557,\n",
              " 'oldie': 11887,\n",
              " 'ldier': 9914,\n",
              " 'dier:': 6114,\n",
              " 'ier: ': 8762,\n",
              " ' orig': 2309,\n",
              " 'origi': 12270,\n",
              " 'rigin': 13598,\n",
              " 'igins': 8834,\n",
              " 'gins ': 7872,\n",
              " ' f9 ': 1081,\n",
              " ' shin': 2819,\n",
              " 'shing': 14353,\n",
              " 'hinge': 8356,\n",
              " 'ingek': 9055,\n",
              " 'ngeki': 11239,\n",
              " 'geki ': 7765,\n",
              " ' kyoj': 1760,\n",
              " 'kyoji': 9768,\n",
              " 'yojin': 16573,\n",
              " 'ojin ': 11840,\n",
              " ' 365 ': 70,\n",
              " ' dni ': 881,\n",
              " ' arch': 254,\n",
              " 'arche': 4481,\n",
              " 'rcher': 13261,\n",
              " ' how ': 1497,\n",
              " ' i ': 1518,\n",
              " ' met ': 2041,\n",
              " ' moth': 2111,\n",
              " 'mothe': 10860,\n",
              " 'other': 12408,\n",
              " 'ther ': 15137,\n",
              " ' cheh': 620,\n",
              " 'chehr': 5500,\n",
              " 'hehre': 8239,\n",
              " 'ehre ': 6636,\n",
              " ' shel': 2810,\n",
              " 'sheld': 14334,\n",
              " 'heldo': 8244,\n",
              " 'eldon': 6682,\n",
              " 'ldon ': 9919,\n",
              " ' batm': 344,\n",
              " 'batma': 4980,\n",
              " 'atman': 4765,\n",
              " 'tman ': 15292,\n",
              " ' mafi': 1924,\n",
              " 'mafia': 10448,\n",
              " 'afia ': 3903,\n",
              " ' mani': 1954,\n",
              " 'manif': 10499,\n",
              " 'anife': 4328,\n",
              " 'nifes': 11324,\n",
              " 'ifest': 8780,\n",
              " 'fest ': 7506,\n",
              " ' s.w.': 2687,\n",
              " 's.w.a': 14097,\n",
              " '.w.a.': 3638,\n",
              " 'w.a.t': 16212,\n",
              " '.a.t.': 3626,\n",
              " 'a.t. ': 3703,\n",
              " ' frid': 1208,\n",
              " 'frida': 7645,\n",
              " 'riday': 13569,\n",
              " 'iday ': 8698,\n",
              " ' ligh': 1835,\n",
              " 'light': 10080,\n",
              " 'ights': 8828,\n",
              " 'ghts ': 7841,\n",
              " ' 9-1-': 101,\n",
              " '9-1-1': 3683,\n",
              " '-1-1 ': 3564,\n",
              " ' heat': 1435,\n",
              " 'heat ': 8228,\n",
              " ' henr': 1444,\n",
              " 'henry': 8264,\n",
              " 'enry ': 6919,\n",
              " ' p.d.': 2335,\n",
              " 'p.d. ': 12586,\n",
              " ' sham': 2800,\n",
              " 'shame': 14315,\n",
              " 'hamel': 8127,\n",
              " 'amele': 4195,\n",
              " 'meles': 10635,\n",
              " 'eless': 6693,\n",
              " 'less ': 9994,\n",
              " ' expa': 1068,\n",
              " 'expan': 7400,\n",
              " 'xpans': 16469,\n",
              " 'panse': 12617,\n",
              " 'anse ': 4371,\n",
              " ' mupp': 2141,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1bKMGwtKAQ3",
        "outputId": "1c03c147-5f7c-478f-b154-66a1a5226304"
      },
      "source": [
        "# Сколько максимально раз одна n-gram встречается в одной и той же строке\n",
        "np.max(bag_of_words.toarray())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4a_YdxFKcjK",
        "outputId": "d8f9e805-fe6a-46d0-eb0e-c02cab29c5a9"
      },
      "source": [
        "# Каждая строка (значение фичи) представляется как вектор длиной = (размер словаря)\n",
        "# Каждый элемент вектора - число:\n",
        "# 0 если в данной строке нет такого слова из словаря.\n",
        "# 1 если в данной строке 1 раз встречается такое слово из словаря.\n",
        "# 2 если в данной строке 2 раза встречается такое слово из словаря, и т.д.\n",
        "# Если задать аргумент binary=True, то количество раз не в счёт, каждый элемент или 0 или 1.\n",
        "\n",
        "count_vectorizer = CountVectorizer(ngram_range=(5,5), analyzer='char_wb', binary=True)\n",
        "\n",
        "bag_of_words = count_vectorizer.fit_transform(cat_imdb_df_2[\"Name\"])\n",
        "bag_of_words.toarray().shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6178, 16716)"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqKZuWmHKjTa",
        "outputId": "00486773-e555-4854-8ed6-8902edce5587"
      },
      "source": [
        "np.max(bag_of_words.toarray())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ymVxrX_rYux",
        "outputId": "04dad167-2e05-4d7f-cc47-122364976037"
      },
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "# Create the Bag-of-Words\n",
        "bag_of_words = count_vectorizer.fit_transform(cat_imdb_df_2[\"Genre\"])\n",
        "bag_of_words.toarray().shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6178, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9R0w86errr2",
        "outputId": "b45b7c18-7bdc-491b-f07d-defa7a0d48a0"
      },
      "source": [
        "count_vectorizer.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['action',\n",
              " 'adventure',\n",
              " 'animation',\n",
              " 'biography',\n",
              " 'comedy',\n",
              " 'crime',\n",
              " 'documentary',\n",
              " 'drama',\n",
              " 'family',\n",
              " 'fantasy',\n",
              " 'fi',\n",
              " 'film',\n",
              " 'game',\n",
              " 'history',\n",
              " 'horror',\n",
              " 'music',\n",
              " 'musical',\n",
              " 'mystery',\n",
              " 'news',\n",
              " 'noir',\n",
              " 'reality',\n",
              " 'romance',\n",
              " 'sci',\n",
              " 'short',\n",
              " 'show',\n",
              " 'sport',\n",
              " 'talk',\n",
              " 'thriller',\n",
              " 'tv',\n",
              " 'war',\n",
              " 'western']"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9l9r52Ehr3kF",
        "outputId": "e0ad324d-ea5a-428b-8ac8-aa63d637959e"
      },
      "source": [
        "count_vectorizer.vocabulary_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'action': 0,\n",
              " 'adventure': 1,\n",
              " 'animation': 2,\n",
              " 'biography': 3,\n",
              " 'comedy': 4,\n",
              " 'crime': 5,\n",
              " 'documentary': 6,\n",
              " 'drama': 7,\n",
              " 'family': 8,\n",
              " 'fantasy': 9,\n",
              " 'fi': 10,\n",
              " 'film': 11,\n",
              " 'game': 12,\n",
              " 'history': 13,\n",
              " 'horror': 14,\n",
              " 'music': 15,\n",
              " 'musical': 16,\n",
              " 'mystery': 17,\n",
              " 'news': 18,\n",
              " 'noir': 19,\n",
              " 'reality': 20,\n",
              " 'romance': 21,\n",
              " 'sci': 22,\n",
              " 'short': 23,\n",
              " 'show': 24,\n",
              " 'sport': 25,\n",
              " 'talk': 26,\n",
              " 'thriller': 27,\n",
              " 'tv': 28,\n",
              " 'war': 29,\n",
              " 'western': 30}"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiLQrZKgr7Gt",
        "outputId": "78f82f98-9d06-4861-e0cf-dfb279ee4b04"
      },
      "source": [
        "first_record = bag_of_words.toarray()[0]\n",
        "first_record\n",
        "# 'action': 0, 'adventure': 1, 'thriller': 27"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JP_2fgj1sCAX",
        "outputId": "a1df6503-2b59-4f10-e3a8-334cbd949488"
      },
      "source": [
        "second_record = bag_of_words.toarray()[1]\n",
        "second_record\n",
        "# 'crime': 5, 'drama': 7, 'thriller': 27"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "er-aTYrUQaL1",
        "outputId": "1ff2ffb9-f134-4211-b1dc-c257b79c6d00"
      },
      "source": [
        "feature_names = count_vectorizer.get_feature_names()\n",
        "pd.DataFrame(bag_of_words.toarray(), columns = feature_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>action</th>\n",
              "      <th>adventure</th>\n",
              "      <th>animation</th>\n",
              "      <th>biography</th>\n",
              "      <th>comedy</th>\n",
              "      <th>crime</th>\n",
              "      <th>documentary</th>\n",
              "      <th>drama</th>\n",
              "      <th>family</th>\n",
              "      <th>fantasy</th>\n",
              "      <th>fi</th>\n",
              "      <th>film</th>\n",
              "      <th>game</th>\n",
              "      <th>history</th>\n",
              "      <th>horror</th>\n",
              "      <th>music</th>\n",
              "      <th>musical</th>\n",
              "      <th>mystery</th>\n",
              "      <th>news</th>\n",
              "      <th>noir</th>\n",
              "      <th>reality</th>\n",
              "      <th>romance</th>\n",
              "      <th>sci</th>\n",
              "      <th>short</th>\n",
              "      <th>show</th>\n",
              "      <th>sport</th>\n",
              "      <th>talk</th>\n",
              "      <th>thriller</th>\n",
              "      <th>tv</th>\n",
              "      <th>war</th>\n",
              "      <th>western</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6173</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6174</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6175</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6176</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6177</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6178 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      action  adventure  animation  biography  ...  thriller  tv  war  western\n",
              "0          1          1          0          0  ...         1   0    0        0\n",
              "1          0          0          0          0  ...         1   0    0        0\n",
              "2          0          0          0          0  ...         0   0    0        0\n",
              "3          1          1          0          0  ...         0   0    0        0\n",
              "4          1          1          0          0  ...         0   0    0        0\n",
              "...      ...        ...        ...        ...  ...       ...  ..  ...      ...\n",
              "6173       0          0          0          0  ...         0   0    0        0\n",
              "6174       0          0          0          0  ...         0   0    0        0\n",
              "6175       0          0          0          0  ...         1   0    0        0\n",
              "6176       0          0          0          0  ...         0   0    0        0\n",
              "6177       1          0          0          0  ...         1   0    0        0\n",
              "\n",
              "[6178 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehEgOV4St9LL",
        "outputId": "2a5ad402-15dc-4862-99ab-00f9de82cdc8"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Create TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "tfidf_result = tfidf_vectorizer.fit_transform(cat_imdb_df_2[\"Genre\"])\n",
        "tfidf_result.toarray().shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6178, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lk7K35p5NgjO",
        "outputId": "6cc15f17-eaa6-464b-bf70-4c8e0a4a0f53"
      },
      "source": [
        "tfidf_vectorizer.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['action',\n",
              " 'adventure',\n",
              " 'animation',\n",
              " 'biography',\n",
              " 'comedy',\n",
              " 'crime',\n",
              " 'documentary',\n",
              " 'drama',\n",
              " 'family',\n",
              " 'fantasy',\n",
              " 'fi',\n",
              " 'film',\n",
              " 'game',\n",
              " 'history',\n",
              " 'horror',\n",
              " 'music',\n",
              " 'musical',\n",
              " 'mystery',\n",
              " 'news',\n",
              " 'noir',\n",
              " 'reality',\n",
              " 'romance',\n",
              " 'sci',\n",
              " 'short',\n",
              " 'show',\n",
              " 'sport',\n",
              " 'talk',\n",
              " 'thriller',\n",
              " 'tv',\n",
              " 'war',\n",
              " 'western']"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74t7F6EAuboI",
        "outputId": "b2770bed-e441-40be-d272-c8eb61993937"
      },
      "source": [
        "tfidf_vectorizer.vocabulary_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'action': 0,\n",
              " 'adventure': 1,\n",
              " 'animation': 2,\n",
              " 'biography': 3,\n",
              " 'comedy': 4,\n",
              " 'crime': 5,\n",
              " 'documentary': 6,\n",
              " 'drama': 7,\n",
              " 'family': 8,\n",
              " 'fantasy': 9,\n",
              " 'fi': 10,\n",
              " 'film': 11,\n",
              " 'game': 12,\n",
              " 'history': 13,\n",
              " 'horror': 14,\n",
              " 'music': 15,\n",
              " 'musical': 16,\n",
              " 'mystery': 17,\n",
              " 'news': 18,\n",
              " 'noir': 19,\n",
              " 'reality': 20,\n",
              " 'romance': 21,\n",
              " 'sci': 22,\n",
              " 'short': 23,\n",
              " 'show': 24,\n",
              " 'sport': 25,\n",
              " 'talk': 26,\n",
              " 'thriller': 27,\n",
              " 'tv': 28,\n",
              " 'war': 29,\n",
              " 'western': 30}"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZtfjEuAOZQ1",
        "outputId": "f27e7855-bfac-4617-d2c6-7db8f9fda5db"
      },
      "source": [
        "# Основное отличие TfidfVectorizer от CountVectorizer в том, что он возвращает\n",
        "# scores (во float), а не counts (в int)\n",
        "\n",
        "first_record = tfidf_result.toarray()[0]\n",
        "first_record\n",
        "# 'action': 0, 'adventure': 1, 'thriller': 27"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.51936916, 0.57543947, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.63176348, 0.        , 0.        ,\n",
              "       0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfEaXmD0OmfZ",
        "outputId": "f884403a-f2ec-4c56-afb4-63f122c77dbc"
      },
      "source": [
        "second_record = tfidf_result.toarray()[1]\n",
        "second_record\n",
        "# 'crime': 5, 'drama': 7, 'thriller': 27"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.62869917, 0.        , 0.39101577, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.67219345, 0.        , 0.        ,\n",
              "       0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "_va9iZE4QEHy",
        "outputId": "682fdb7d-df4e-4c9e-df04-5d4aaaeaf8a0"
      },
      "source": [
        "feature_names = tfidf_vectorizer.get_feature_names()\n",
        "pd.DataFrame(tfidf_result.toarray(), columns = feature_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>action</th>\n",
              "      <th>adventure</th>\n",
              "      <th>animation</th>\n",
              "      <th>biography</th>\n",
              "      <th>comedy</th>\n",
              "      <th>crime</th>\n",
              "      <th>documentary</th>\n",
              "      <th>drama</th>\n",
              "      <th>family</th>\n",
              "      <th>fantasy</th>\n",
              "      <th>fi</th>\n",
              "      <th>film</th>\n",
              "      <th>game</th>\n",
              "      <th>history</th>\n",
              "      <th>horror</th>\n",
              "      <th>music</th>\n",
              "      <th>musical</th>\n",
              "      <th>mystery</th>\n",
              "      <th>news</th>\n",
              "      <th>noir</th>\n",
              "      <th>reality</th>\n",
              "      <th>romance</th>\n",
              "      <th>sci</th>\n",
              "      <th>short</th>\n",
              "      <th>show</th>\n",
              "      <th>sport</th>\n",
              "      <th>talk</th>\n",
              "      <th>thriller</th>\n",
              "      <th>tv</th>\n",
              "      <th>war</th>\n",
              "      <th>western</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.519369</td>\n",
              "      <td>0.575439</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.631763</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.628699</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.391016</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.672193</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.849163</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.528132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.392580</td>\n",
              "      <td>0.434963</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.573013</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.573013</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.605422</td>\n",
              "      <td>0.670782</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.428387</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6173</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6174</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.233971</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.145517</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.679736</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.679736</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6175</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.628699</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.391016</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.672193</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6176</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.519895</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.399047</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.755295</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6177</th>\n",
              "      <td>0.385170</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.562197</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.562197</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.468523</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6178 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        action  adventure  animation  biography  ...  thriller   tv  war  western\n",
              "0     0.519369   0.575439        0.0        0.0  ...  0.631763  0.0  0.0      0.0\n",
              "1     0.000000   0.000000        0.0        0.0  ...  0.672193  0.0  0.0      0.0\n",
              "2     0.000000   0.000000        0.0        0.0  ...  0.000000  0.0  0.0      0.0\n",
              "3     0.392580   0.434963        0.0        0.0  ...  0.000000  0.0  0.0      0.0\n",
              "4     0.605422   0.670782        0.0        0.0  ...  0.000000  0.0  0.0      0.0\n",
              "...        ...        ...        ...        ...  ...       ...  ...  ...      ...\n",
              "6173  0.000000   0.000000        0.0        0.0  ...  0.000000  0.0  0.0      0.0\n",
              "6174  0.000000   0.000000        0.0        0.0  ...  0.000000  0.0  0.0      0.0\n",
              "6175  0.000000   0.000000        0.0        0.0  ...  0.672193  0.0  0.0      0.0\n",
              "6176  0.000000   0.000000        0.0        0.0  ...  0.000000  0.0  0.0      0.0\n",
              "6177  0.385170   0.000000        0.0        0.0  ...  0.468523  0.0  0.0      0.0\n",
              "\n",
              "[6178 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSg4wkcA-2q-"
      },
      "source": [
        "## Encoding categorical features in TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XqUB4e51AP_W",
        "outputId": "4ab671d6-b17e-4e1c-93b2-abe4529cf5a3"
      },
      "source": [
        "cat_imdb_df_5 = cat_imdb_df_2.copy()\n",
        "cat_imdb_df_5.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Certificate</th>\n",
              "      <th>Nudity</th>\n",
              "      <th>Violence</th>\n",
              "      <th>Profanity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No Time to Die</td>\n",
              "      <td>Action, Adventure, Thriller</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>0</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Mild</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Guilty</td>\n",
              "      <td>Crime, Drama, Thriller</td>\n",
              "      <td>R</td>\n",
              "      <td>3</td>\n",
              "      <td>None</td>\n",
              "      <td>Severe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Many Saints of Newark</td>\n",
              "      <td>Crime, Drama</td>\n",
              "      <td>R</td>\n",
              "      <td>1</td>\n",
              "      <td>Severe</td>\n",
              "      <td>Severe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Venom: Let There Be Carnage</td>\n",
              "      <td>Action, Adventure, Sci-Fi</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>3</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Moderate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dune</td>\n",
              "      <td>Action, Adventure, Drama</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>3</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Name                        Genre  ...  Violence  Profanity\n",
              "0               No Time to Die  Action, Adventure, Thriller  ...  Moderate       Mild\n",
              "1                   The Guilty       Crime, Drama, Thriller  ...      None     Severe\n",
              "2    The Many Saints of Newark                 Crime, Drama  ...    Severe     Severe\n",
              "3  Venom: Let There Be Carnage    Action, Adventure, Sci-Fi  ...  Moderate   Moderate\n",
              "4                         Dune     Action, Adventure, Drama  ...  Moderate       None\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MGG2c1yAWj4",
        "outputId": "49b4308b-edfe-4efd-c254-fc51b109dd8b"
      },
      "source": [
        "cat_imdb_df_5[\"Violence\"].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Moderate', 'None', 'Severe', 'No Rate', 'Mild'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wNZmMZ8BJTc"
      },
      "source": [
        "number_unique_categories = len(cat_imdb_df_5[\"Violence\"].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_S9WWIw-5BQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5dff2a6-e370-4437-92fb-ded05a934e69"
      },
      "source": [
        "indices = tf.range(number_unique_categories, dtype=tf.int64)\n",
        "indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([0, 1, 2, 3, 4])>"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Quoplkv2D4EO",
        "outputId": "8bda1c2f-9a1c-4479-eb2b-f427feeaabaa"
      },
      "source": [
        "vocab = cat_imdb_df_5[\"Violence\"].unique()\n",
        "keys_tensor = tf.constant(vocab)\n",
        "keys_tensor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=string, numpy=array([b'Moderate', b'None', b'Severe', b'No Rate', b'Mild'], dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jq0NCf8G_Alo"
      },
      "source": [
        "table_init = tf.lookup.KeyValueTensorInitializer(keys_tensor, indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oSswi65_D75"
      },
      "source": [
        "num_oov_buckets = 2\n",
        "table = tf.lookup.StaticVocabularyTable(table_init, num_oov_buckets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBoT3DGE_HTl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36b1db2f-d761-4693-ede9-e7664aac8b4d"
      },
      "source": [
        "# Encoding to ints\n",
        "\n",
        "# There are indices for unknown words due to oov_buckets\n",
        "category_values = tf.constant(['Moderate', 'Sex', 'Severe'])\n",
        "cat_indices = table.lookup(category_values)\n",
        "cat_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=int64, numpy=array([0, 6, 2])>"
            ]
          },
          "metadata": {},
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftfCz04PB3PC",
        "outputId": "88243ec9-4008-4bf0-babb-f9340b3519b9"
      },
      "source": [
        "category_values = tf.constant(cat_imdb_df_5[\"Violence\"])\n",
        "cat_indices = table.lookup(category_values)\n",
        "cat_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6178,), dtype=int64, numpy=array([0, 1, 2, ..., 0, 1, 2])>"
            ]
          },
          "metadata": {},
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaxx83CP_mw9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad60f4bd-668b-412f-e3f2-b048175afa57"
      },
      "source": [
        "# Encoding to one-hot\n",
        "\n",
        "# tf.one_hot does not accept the categories themselves, but instead accepts a list of indices\n",
        "cat_one_hot = tf.one_hot(cat_indices, depth=number_unique_categories+num_oov_buckets )\n",
        "cat_one_hot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6178, 7), dtype=float32, numpy=\n",
              "array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJqb_6LrGBRV",
        "outputId": "6a6acae5-c410-43d8-bf46-ee491502278c"
      },
      "source": [
        "# Verify for 'Moderate' - 1 0 0 0 0 0 0\n",
        "cat_one_hot[4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(7,), dtype=float32, numpy=array([1., 0., 0., 0., 0., 0., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yg8X4C32bebY",
        "outputId": "a38c83ee-967d-4a73-9850-6fdf85b9357d"
      },
      "source": [
        "# tf.keras.preprocessing.text.one_hot\n",
        "\n",
        "# It's hard to name this one-hot, but nevertheless there is the such function\n",
        "\n",
        "tf.keras.preprocessing.text.one_hot(\"Some string\", 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8, 6]"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM7j5x2mfE2s",
        "outputId": "2aee294b-62c3-48c0-f36e-5ffadf7f4c40"
      },
      "source": [
        "tf.keras.preprocessing.text.one_hot(\"Some string\", 500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[53, 141]"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQEyXsYRd-S7",
        "outputId": "ed599fcc-a834-42c8-8ee7-04df823663a7"
      },
      "source": [
        "# It's more likely than not to use it as preprocessing for one-hot\n",
        "\n",
        "size_vocabulary = 10\n",
        "\n",
        "list_ints_1 = tf.keras.preprocessing.text.one_hot(\"Some string\", size_vocabulary)\n",
        "list_ints_2 = tf.keras.preprocessing.text.one_hot(\"Another message\", size_vocabulary)\n",
        "\n",
        "cat_one_hot = tf.one_hot(list_ints_1, depth=size_vocabulary)\n",
        "cat_one_hot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LThQAeRgepZT",
        "outputId": "afdb674f-481e-44c5-aeba-2bcc0068bef4"
      },
      "source": [
        "cat_one_hot = tf.one_hot(list_ints_2, depth=size_vocabulary)\n",
        "cat_one_hot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
              "array([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf4G1PDTDJUN"
      },
      "source": [
        "### Encoding categorical features using TextVectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HCvEJ0j3DWsI",
        "outputId": "30464c79-6cc5-4371-be94-df2b67e0da3b"
      },
      "source": [
        "cat_imdb_df_6 = cat_imdb_df.copy()\n",
        "cat_imdb_df_6.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Certificate</th>\n",
              "      <th>Nudity</th>\n",
              "      <th>Violence</th>\n",
              "      <th>Profanity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No Time to Die</td>\n",
              "      <td>Action, Adventure, Thriller</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>Mild</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Mild</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Guilty</td>\n",
              "      <td>Crime, Drama, Thriller</td>\n",
              "      <td>R</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Severe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Many Saints of Newark</td>\n",
              "      <td>Crime, Drama</td>\n",
              "      <td>R</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Severe</td>\n",
              "      <td>Severe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Venom: Let There Be Carnage</td>\n",
              "      <td>Action, Adventure, Sci-Fi</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>None</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Moderate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dune</td>\n",
              "      <td>Action, Adventure, Drama</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>None</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Name                        Genre  ...  Violence Profanity\n",
              "0               No Time to Die  Action, Adventure, Thriller  ...  Moderate      Mild\n",
              "1                   The Guilty       Crime, Drama, Thriller  ...      None    Severe\n",
              "2    The Many Saints of Newark                 Crime, Drama  ...    Severe    Severe\n",
              "3  Venom: Let There Be Carnage    Action, Adventure, Sci-Fi  ...  Moderate  Moderate\n",
              "4                         Dune     Action, Adventure, Drama  ...  Moderate      None\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgmQtWHyDjTy",
        "outputId": "ab9f5cd0-3ac9-4226-f657-917225eed0a1"
      },
      "source": [
        "# tf.keras.layers.TextVectorization(\n",
        "#     max_tokens=None, standardize='lower_and_strip_punctuation',\n",
        "#     split='whitespace', ngrams=None, output_mode='int',\n",
        "#     output_sequence_length=None, pad_to_max_tokens=False, vocabulary=None, **kwargs\n",
        "# )\n",
        "\n",
        "# It transforms a batch of strings (one example = one string) into either a list\n",
        "# of token indices (one example = 1D tensor of integer token indices) or\n",
        "# a dense representation (one example = 1D tensor of float values\n",
        "# representing data about the example's tokens).\n",
        "\n",
        "# If desired, the user can call this layer's adapt() method on a dataset.\n",
        "# When this layer is adapted, it will analyze the dataset,\n",
        "# determine the frequency of individual string values,\n",
        "# and create a 'vocabulary' from them.\n",
        "# This vocabulary can have unlimited size or be capped,\n",
        "# depending on the configuration options for this layer;\n",
        "# if there are more unique values in the input than the maximum vocabulary size,\n",
        "# the most frequent terms will be used to create the vocabulary.\n",
        "\n",
        "# The processing of each example contains the following steps:\n",
        "\n",
        "  # Standardize each example (usually lowercasing + punctuation stripping);\n",
        "  # Split each example into substrings (usually words);\n",
        "  # Recombine substrings into tokens (usually ngrams);\n",
        "  # Index tokens (associate a unique int value with each token);\n",
        "  # Transform each example using this index, either into a vector of ints\n",
        "  # or a dense float vector.\n",
        "\n",
        "# max_tokens - The maximum size of the vocabulary for this layer.\n",
        "# If None, there is no cap on the size of the vocabulary.\n",
        "\n",
        "# standardize - Optional specification for standardization to apply to the input text.\n",
        "# Values can be None (no standardization),\n",
        "# \"lower_and_strip_punctuation\" (lowercase and remove punctuation) or a Callable.\n",
        "# Default is \"lower_and_strip_punctuation\".\n",
        "\n",
        "# split - Optional specification for splitting the input text.\n",
        "# Values can be None (no splitting), \"whitespace\" (split on ASCII whitespace),\n",
        "# or a Callable.\n",
        "# The default is \"whitespace\".\n",
        "\n",
        "# ngrams - Optional specification for ngrams to create from the possibly-split input text.\n",
        "# Values can be None, an integer or tuple of integers;\n",
        "# passing an integer will create ngrams up to that integer,\n",
        "# and passing a tuple of integers will create ngrams for the specified values in the tuple.\n",
        "# Passing None means that no ngrams will be created.\n",
        "\n",
        "# output_mode:\n",
        "\n",
        "    # \"int\": Outputs integer indices, one integer index per split string token.\n",
        "    # When output_mode == \"int\", 0 is reserved for masked locations;\n",
        "    # this reduces the vocab size to max_tokens - 2 instead of max_tokens - 1.\n",
        "\n",
        "    # \"multi_hot\": Outputs a single int array per batch,\n",
        "    # of either vocab_size or max_tokens size,\n",
        "    # containing Ones in all elements where the token mapped to that index exists\n",
        "    # at least once in the batch item.\n",
        "\n",
        "    # \"count\": Like \"multi_hot\", but the int array contains a count of the number\n",
        "    # of times the token at that index appeared in the batch item.\n",
        "\n",
        "    # \"tf_idf\": Like \"multi_hot\", but the TF-IDF algorithm is applied to find\n",
        "    # the value in each token slot.\n",
        "    \n",
        "    # For \"int\" output, any shape of input and output is supported.\n",
        "    # For all other output modes, currently only rank 1 inputs\n",
        "    # (and rank 2 outputs after splitting) are supported.\n",
        "\n",
        "# output_sequence_length - Only valid in INT mode. If set, the output will have\n",
        "# its time dimension padded or truncated to exactly output_sequence_length values,\n",
        "# resulting in a tensor of shape (batch_size, output_sequence_length) regardless\n",
        "# of how many tokens resulted from the splitting step. Defaults to None.\n",
        "\n",
        "# pad_to_max_tokens - Only valid in \"multi_hot\", \"count\", and \"tf_idf\" modes.\n",
        "# If True, the output will have its feature axis padded to max_tokens even if\n",
        "# the number of unique tokens in the vocabulary is less than max_tokens,\n",
        "# resulting in a tensor of shape (batch_size, max_tokens) regardless of vocabulary size.\n",
        "# Defaults to False.\n",
        "\n",
        "# vocabulary - Optional. Either an array of strings or a string path to a text file.\n",
        "\n",
        "\n",
        "text_vectorizer = tf.keras.layers.TextVectorization()\n",
        "text_vectorizer.adapt(cat_imdb_df_6['Nudity'])\n",
        "text_vectorizer.call(cat_imdb_df_6['Violence'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6178, 2), dtype=int64, numpy=\n",
              "array([[4, 0],\n",
              "       [3, 0],\n",
              "       [7, 0],\n",
              "       ...,\n",
              "       [4, 0],\n",
              "       [3, 0],\n",
              "       [7, 0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_p8llctOvQ-",
        "outputId": "6b1560b5-08bd-47f9-eded-987a7ded629e"
      },
      "source": [
        "# Как видим, по умолчанию строки разделяются на слова (дефолтное разделение - пробел)\n",
        "# Каждое уникальное слово (в пределах батча) в обучающей выборке\n",
        "# получает свой уникальный индекс (целое число)\n",
        "# Один индекс (1 oov-bucket) выделяется для неизвестных слов\n",
        "\n",
        "text_vectorizer.get_vocabulary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'mild', 'none', 'moderate', 'rate', 'no', 'severe']"
            ]
          },
          "metadata": {},
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPTgAQJbFTz2",
        "outputId": "a0a3b100-14a0-4a9f-c155-6a398fbde8de"
      },
      "source": [
        "# Каждый вектор содержит 0 в позициях, для которых не найдено слов в словаре\n",
        "# или число (числа), соответствующие найденным индексам в словаре.\n",
        "# Размер выходных векторов определяется размером самой длинной строки среди строк\n",
        "# на входе метода call().\n",
        "# В данном случае максимальная строка - из двух слов.\n",
        "\n",
        "# Вот та самая строка из двух слов в выборке cat_imdb_df_6['Violence'] \n",
        "text_vectorizer.call(['No Rate'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=int64, numpy=array([[6, 5]])>"
            ]
          },
          "metadata": {},
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn_JGG9ZImwu",
        "outputId": "ad314c38-c77a-4220-9a05-fcd2a2809d0f"
      },
      "source": [
        "# Одно слово найдено\n",
        "text_vectorizer.call(['Rate'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[5]])>"
            ]
          },
          "metadata": {},
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LT7FHiJGx6m",
        "outputId": "70fc8d21-1afb-4ae0-9cc4-f2b0de02a058"
      },
      "source": [
        "# Два слова найдены\n",
        "text_vectorizer.call(['Rate Severe'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=int64, numpy=array([[5, 7]])>"
            ]
          },
          "metadata": {},
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-NceJrvIonR",
        "outputId": "3f761ced-93b8-4158-cbd3-af211eb49fbb"
      },
      "source": [
        "# Обращаем внимание, что если на входе call() только строки длиной 1,\n",
        "# то и выходные вектора имеют длину 1\n",
        "text_vectorizer.call([['Rate'], ['No']])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 1), dtype=int64, numpy=\n",
              "array([[5],\n",
              "       [6]])>"
            ]
          },
          "metadata": {},
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWjqiCtOGoyI",
        "outputId": "cadbc933-d685-4a94-9d80-94d0fe46a533"
      },
      "source": [
        "# А если хотя бы одна из входных строк длиннее других,\n",
        "# то ширина выходной матрицы равна максимальной длине строки\n",
        "text_vectorizer.call([['Rate'], ['No Rate']])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int64, numpy=\n",
              "array([[5, 0],\n",
              "       [6, 5]])>"
            ]
          },
          "metadata": {},
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7VOVIoqHiP9",
        "outputId": "1c260599-7574-4385-bae6-2391409cfa16"
      },
      "source": [
        "# Незнакомое слово найдено\n",
        "text_vectorizer.call(['Rate Good'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=int64, numpy=array([[5, 1]])>"
            ]
          },
          "metadata": {},
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jN7YKPWkQves",
        "outputId": "af975334-949b-42d4-cc94-d52cabdb2eef"
      },
      "source": [
        "# Можно задать явно размер выходного вектора (только для output_mode='int')\n",
        "\n",
        "text_vectorizer = tf.keras.layers.TextVectorization(output_sequence_length=1)\n",
        "text_vectorizer.adapt(cat_imdb_df_6['Nudity'])\n",
        "text_vectorizer.call(cat_imdb_df_6['Violence'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6178, 1), dtype=int64, numpy=\n",
              "array([[4],\n",
              "       [3],\n",
              "       [7],\n",
              "       ...,\n",
              "       [4],\n",
              "       [3],\n",
              "       [7]])>"
            ]
          },
          "metadata": {},
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkLIGmNpFECY",
        "outputId": "65a68907-4961-450a-c548-f91063d34988"
      },
      "source": [
        "# И тогда выходной вектор или дополняется нулями справа (если строка короче)\n",
        "# или усекается (остаются только крайние левые столбцы), т.е. лишние (справа) слова отбрасываются\n",
        "text_vectorizer.call(['No Rate'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[6]])>"
            ]
          },
          "metadata": {},
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3JcpkHfKR56",
        "outputId": "d6e62376-a77e-4cc5-9b5c-e719346ce98c"
      },
      "source": [
        "text_vectorizer.call(['Rate Severe'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[5]])>"
            ]
          },
          "metadata": {},
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gozEarRDSlc",
        "outputId": "7235c07e-00e7-4013-caa6-edd01ef35208"
      },
      "source": [
        "text_vectorizer = tf.keras.layers.TextVectorization(output_sequence_length=10)\n",
        "text_vectorizer.adapt(cat_imdb_df_6['Nudity'])\n",
        "text_vectorizer.call(cat_imdb_df_6['Violence'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6178, 10), dtype=int64, numpy=\n",
              "array([[4, 0, 0, ..., 0, 0, 0],\n",
              "       [3, 0, 0, ..., 0, 0, 0],\n",
              "       [7, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [4, 0, 0, ..., 0, 0, 0],\n",
              "       [3, 0, 0, ..., 0, 0, 0],\n",
              "       [7, 0, 0, ..., 0, 0, 0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OegKYTvuSWlE",
        "outputId": "9413cb6f-785a-4263-ac31-a9e356542d8d"
      },
      "source": [
        "# В режиме multi_hot получаем представление строк в виде bag-of-words,\n",
        "# но в режиме binary=True.\n",
        "# Как видим, здесь длина вектора зависит от длины словаря\n",
        "\n",
        "text_vectorizer = tf.keras.layers.TextVectorization(output_mode='multi_hot')\n",
        "text_vectorizer.adapt(cat_imdb_df_6['Nudity'])\n",
        "text_vectorizer.call(cat_imdb_df_6['Violence'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6178, 7), dtype=float32, numpy=\n",
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sOYGdy9S1ce",
        "outputId": "5054a59d-f23d-4c43-cbae-d9560688ed14"
      },
      "source": [
        "# Здесь в строке 2 слова из словаря и одно незнакомое слово (размер словаря - 7)\n",
        "# Одно из слов встречается 2 раза\n",
        "text_vectorizer.call([['Mild Moderate Sex Mild']])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 7), dtype=float32, numpy=array([[1., 1., 0., 1., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcLLbm2TTn6B",
        "outputId": "1482d6e6-7741-4407-ecfd-8cfa0169f39c"
      },
      "source": [
        "# В режиме count получаем представление строк в виде bag-of-words\n",
        "# Как видим, здесь длина вектора зависит от длины словаря\n",
        "\n",
        "text_vectorizer = tf.keras.layers.TextVectorization(output_mode='count')\n",
        "text_vectorizer.adapt(cat_imdb_df_6['Nudity'])\n",
        "text_vectorizer.call(cat_imdb_df_6['Violence'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6178, 7), dtype=float32, numpy=\n",
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdurd28dU6Mm",
        "outputId": "865ff414-2b61-4cfb-bb65-1979f738b93d"
      },
      "source": [
        "# Здесь в строке 2 слова из словаря и одно незнакомое слово (размер словаря - 7)\n",
        "# И одно слово встречается 2 раза (count=2)\n",
        "text_vectorizer.call([['Mild Moderate Sex Mild']])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 7), dtype=float32, numpy=array([[1., 2., 0., 1., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClE-04JTVaxl",
        "outputId": "8a9f222b-3385-403a-9105-2183eff3b4ae"
      },
      "source": [
        "# На выходе слоя TextVectorization получаем обычный тензор, не sparse tensor\n",
        "# В дефолтном режиме 'int' длина вектора равна максимальной длине строки\n",
        "text_vectorizer = tf.keras.layers.TextVectorization()\n",
        "text_vectorizer.adapt(cat_imdb_df_6['Name'])\n",
        "result = text_vectorizer.call(cat_imdb_df_6['Name'])\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6178, 18), dtype=int64, numpy=\n",
              "array([[  10,   39,    8, ...,    0,    0,    0],\n",
              "       [   2,  708,    0, ...,    0,    0,    0],\n",
              "       [   2, 3603, 1508, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [ 158,    2,  268, ...,    0,    0,    0],\n",
              "       [ 147, 2356,    0, ...,    0,    0,    0],\n",
              "       [  70,  368,    0, ...,    0,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ve9nj3W1V62f",
        "outputId": "1f294a0f-9858-4e0a-fb2c-6f71cc320a1d"
      },
      "source": [
        "# В режиме 'multi_hot' длина вектора равна длине словаря\n",
        "text_vectorizer = tf.keras.layers.TextVectorization(output_mode='multi_hot')\n",
        "text_vectorizer.adapt(cat_imdb_df_6['Name'])\n",
        "result = text_vectorizer.call(cat_imdb_df_6['Name'])\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6178, 5012), dtype=float32, numpy=\n",
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 1., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 239
        }
      ]
    }
  ]
}